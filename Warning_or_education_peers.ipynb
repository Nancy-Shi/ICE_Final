{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nancy-Shi/ICE_Final/blob/main/Warning_or_education_peers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA_qQY-h8rAL"
      },
      "source": [
        "## 3-Layer Model with Informtion, Behavior, Disease"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g11ZaIClRcxA"
      },
      "outputs": [],
      "source": [
        "#!pip install hypernetx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_urRNwzCmJK"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvbMl01j8mD4"
      },
      "outputs": [],
      "source": [
        "import hypernetx as hnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fan2mZxpB3Up"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import random\n",
        "import math as math\n",
        "from math import log\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.ticker as ticker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUCtz8IJ8VkT"
      },
      "source": [
        "\n",
        "## Part 1: Hypergraph Generation\n",
        "The following steps generate a hyper graph using the XGI/HyperNetX python package,  following power-law degree distribution for predifined number of nodes n, number of hyperedges num_hyper_edges, degree exponent gamma, using a configuration model with data stored in a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qvT8MAI8VEs"
      },
      "outputs": [],
      "source": [
        "# Step 1: Generate Degree Sequence\n",
        "def generate_degree_sequence(n, gamma, kmin):\n",
        "    # Generate a random set from the power law distribution\n",
        "    u = np.random.uniform(size=n)\n",
        "    degrees = np.ceil((1.0 - u) ** (-1.0 / (gamma - 1.0)))\n",
        "\n",
        "    # Adjust degrees based on the minimum and maximum degree values\n",
        "    kmax = int(np.sqrt(n))\n",
        "    #kmax = int(((gamma-1)/(gamma-2) * n )** (1/gamma))  # max degree\n",
        "    degrees = degrees[(degrees >= kmin) & (degrees <= kmax)].astype(int)\n",
        "\n",
        "    if len(degrees) >= n:\n",
        "        degrees = degrees[:n]\n",
        "    else:\n",
        "        degrees = np.concatenate((degrees, np.full(n - len(degrees), kmin)))\n",
        "\n",
        "    return degrees.tolist()\n",
        "\n",
        "# Step 2: Generate Hyper Edge Size Sequence\n",
        "def generate_hyper_edge_sizes(degrees, num_hyper_edges):\n",
        "    total_degrees = sum(degrees)\n",
        "    hyper_edge_sizes = []\n",
        "    avg_size = total_degrees // num_hyper_edges\n",
        "    remainder = total_degrees % num_hyper_edges\n",
        "    min_size = 2  # Lower bound of the range\n",
        "    max_size = int(np.sqrt(total_degrees))  # Upper bound of the range\n",
        "\n",
        "    for _ in range(num_hyper_edges):\n",
        "        size = random.randint(min_size, max_size)\n",
        "        hyper_edge_sizes.append(size)\n",
        "\n",
        "    return hyper_edge_sizes\n",
        "\n",
        "\n",
        "# Step 3: Create Copies of Nodes\n",
        "def create_node_copies(degrees):\n",
        "    node_copies = []\n",
        "    for i, degree in enumerate(degrees):\n",
        "        for _ in range(degree):\n",
        "            node_copies.append(i)\n",
        "    return node_copies\n",
        "\n",
        "# Step 4: Create Copies of Hyper Edges\n",
        "def create_hyper_edge_copies(hyper_edge_sizes):\n",
        "    hyper_edge_copies = []\n",
        "    for i, size in enumerate(hyper_edge_sizes):\n",
        "        for _ in range(size):\n",
        "            hyper_edge_copies.append(i)\n",
        "    return hyper_edge_copies\n",
        "\n",
        "# Step 5: Randomly Pair Copies without Repeated Pairs\n",
        "def randomly_pair_copies(node_copies, hyper_edge_copies):\n",
        "    pairs = []\n",
        "    paired_hyper_edges = {}\n",
        "\n",
        "    for node_copy in node_copies:\n",
        "        available_hyper_edges = [h for h in hyper_edge_copies if (h, node_copy) not in paired_hyper_edges]\n",
        "\n",
        "        if not available_hyper_edges:\n",
        "            paired_hyper_edges = {}\n",
        "            available_hyper_edges = [h for h in hyper_edge_copies if (h, node_copy) not in paired_hyper_edges]\n",
        "\n",
        "        chosen_hyper_edge = random.choice(available_hyper_edges)\n",
        "        pairs.append((node_copy, chosen_hyper_edge))\n",
        "\n",
        "        paired_hyper_edges[(chosen_hyper_edge, node_copy)] = True\n",
        "        hyper_edge_copies.remove(chosen_hyper_edge)\n",
        "\n",
        "    return pairs\n",
        "\n",
        "# Step 6: Convert Bipartite Graph to A Hypergraph Dictionary\n",
        "def convert_to_hypergraph(pairs):\n",
        "    hypergraph = {}\n",
        "    for pair in pairs:\n",
        "        node, hyper_edge = pair\n",
        "        if hyper_edge in hypergraph:\n",
        "            hypergraph[hyper_edge].append(node)\n",
        "        else:\n",
        "            hypergraph[hyper_edge] = [node]\n",
        "    return hypergraph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b6c7yfU8hg8"
      },
      "outputs": [],
      "source": [
        "def build_hypergraph(n, gamma, kmin, num_hyper_edges):\n",
        "    # Step 1: Generate Degree Sequence\n",
        "    degrees = generate_degree_sequence(n, gamma, kmin)\n",
        "    print(\"Degree Sequence: \", degrees)\n",
        "\n",
        "    # Step 2: Generate Hyper Edge Size Sequence\n",
        "    hyper_edge_sizes = generate_hyper_edge_sizes(degrees, num_hyper_edges)\n",
        "    print(\"Hyper Edge Sizes: \", hyper_edge_sizes)\n",
        "\n",
        "    # Step 3: Create Copies of Nodes\n",
        "    node_copies = create_node_copies(degrees)\n",
        "\n",
        "    # Step 4: Create Copies of Hyper Edges\n",
        "    hyper_edge_copies = create_hyper_edge_copies(hyper_edge_sizes)\n",
        "\n",
        "    # Step 5: Randomly Pair Copies\n",
        "    pairs = randomly_pair_copies(node_copies, hyper_edge_copies)\n",
        "\n",
        "    # Step 6: Convert Bipartite Graph to Hypergraph\n",
        "    hyperedge_dict = convert_to_hypergraph(pairs)\n",
        "\n",
        "    # Print the resulting hypergraph\n",
        "    print(\"Hypergraph Dictionary: \", hyperedge_dict)\n",
        "\n",
        "    return degrees, hyperedge_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-tEXGpf819Y",
        "outputId": "60438def-cb80-4982-f840-b4900ad366ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Degree Sequence:  [3, 5, 3, 3, 4, 3, 7, 8, 13, 3, 3, 3, 3, 4, 4, 3, 4, 3, 4, 3, 3, 3, 3, 13, 3, 6, 3, 5, 3, 3, 12, 3, 3, 8, 3, 3, 4, 3, 3, 4, 8, 5, 4, 3, 9, 3, 4, 6, 4, 3, 6, 3, 4, 3, 3, 3, 4, 11, 14, 7, 4, 3, 4, 4, 3, 4, 4, 15, 3, 4, 3, 10, 5, 3, 6, 8, 3, 9, 3, 3, 4, 4, 3, 21, 3, 8, 5, 3, 4, 7, 3, 5, 5, 5, 4, 6, 4, 8, 5, 4, 3, 6, 3, 4, 3, 5, 7, 3, 3, 3, 3, 3, 6, 3, 3, 11, 14, 3, 8, 4, 3, 3, 4, 9, 3, 3, 3, 3, 3, 3, 4, 7, 3, 11, 5, 3, 4, 3, 3, 3, 3, 3, 3, 4, 3, 3, 13, 3, 4, 20, 5, 3, 3, 3, 11, 3, 4, 3, 3, 4, 4, 3, 5, 3, 4, 6, 3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
            "Hyper Edge Sizes:  [23, 31, 12, 13, 19, 10, 9, 37, 37, 15, 11, 28, 18, 15, 19, 24, 22, 25, 11, 8, 28, 17, 27, 28, 13, 30, 12, 18, 26, 38, 36, 25, 38, 35, 20, 17, 27, 13, 8, 42, 25, 26, 42, 30, 32, 26, 26, 26, 21, 27, 26, 4, 7, 34, 10, 12, 27, 31, 26, 16, 36, 17, 14, 16, 39, 36, 18, 31, 13, 18, 30, 32, 32, 14, 23, 2, 22, 18, 7, 15, 29, 4, 14, 4, 14, 26, 34, 19, 2, 16, 4, 23, 38, 39, 30, 16, 8, 33, 29, 33, 37, 39, 5, 10, 16, 35, 32, 35, 10, 4, 28, 25, 36, 7, 41, 21, 33, 7, 38, 30, 11, 40, 24, 11, 31, 7, 31, 6, 7, 3, 39, 13, 38, 34, 12, 7, 15, 3, 19, 34, 15, 30, 3, 24, 18, 39, 12, 35, 35, 33, 38, 23, 4, 27, 30, 16, 15, 3, 34, 6, 4, 26, 20, 39, 36, 18, 23, 9, 24, 23, 18, 33, 28, 26, 11, 32, 39, 31, 4, 42, 25, 14, 11, 21, 19, 9, 27, 32, 9, 21, 7, 3, 15, 28, 41, 18, 34, 34, 9, 38, 16, 20, 5, 38, 35, 2, 41, 26, 24, 11, 34, 26, 33, 11, 24, 23, 10, 38, 42, 16, 37, 30, 22, 10, 33, 19, 26, 34, 18, 2, 12, 33, 11, 4, 31, 33, 2, 33, 19, 3, 15, 34, 39, 20, 26, 27, 22, 42, 36, 27, 40, 31, 7, 30, 32, 27, 22, 26, 32, 30, 38, 22, 42, 11, 25, 41, 12, 4, 7, 29, 8, 35, 8, 17, 27, 42, 33, 18, 7, 39, 38, 17, 37, 42, 26, 26, 37, 2, 11, 32, 18, 42, 31, 6, 21, 42, 28, 8, 42, 37]\n",
            "Hypergraph Dictionary:  {211: [0, 30, 249, 408, 414], 74: [0, 18, 269, 420], 131: [0, 111], 253: [1, 33, 47, 70, 94, 143, 260, 335], 15: [1, 5, 131, 169, 195, 408], 53: [1, 50, 60, 251, 319], 269: [1, 3, 75, 77, 163, 241, 436, 466, 477], 214: [1, 54, 83, 146, 149, 160, 284], 20: [2, 39, 70, 122, 155, 230, 342, 457, 497], 70: [2, 12, 42, 115, 146, 153, 191, 217, 240, 343, 444, 465], 183: [2, 11, 14, 214], 110: [3, 8, 23, 61, 69, 133, 196, 204, 364], 112: [3, 95, 155, 189, 298, 340, 372, 454], 107: [4, 11, 53, 57, 85, 130, 158, 192, 225, 324], 185: [4, 51], 141: [4, 44, 166, 195, 348, 448], 289: [4, 86, 134, 147, 186, 244, 325, 466], 243: [5, 73, 460], 116: [5, 8, 16, 17, 29, 45, 126, 129, 138, 154, 227, 316, 403, 434], 73: [6, 58, 200, 419], 221: [6, 10, 58, 82, 83, 93, 95, 96, 103, 146, 191, 207, 268, 350, 375, 429], 254: [6, 52, 57, 60, 74, 180, 205, 288, 373], 170: [6, 114, 121, 276, 336, 398], 50: [6, 97, 245, 274, 285, 330, 361, 374, 452, 482], 234: [6, 85, 243, 296, 352, 381], 99: [6, 137, 143, 230, 459, 475, 490, 499], 265: [7, 8, 47, 87, 116, 134, 264, 279, 428, 477], 0: [7, 57, 83, 85, 178, 284, 341, 371, 374, 379], 14: [7, 33, 76, 160, 385, 486], 164: [7, 30, 48, 52, 81, 83, 179, 241, 336, 359, 376, 470, 475], 148: [7, 69, 77, 106, 165, 224, 302, 364, 402, 467], 255: [7, 14, 19, 28, 87, 187, 197, 346, 444, 487, 496], 230: [7, 74, 96, 97, 99], 89: [7, 59, 317, 350, 495], 284: [8, 71, 137, 150, 216, 238, 286, 387, 474], 86: [8, 63, 67, 71, 75, 83, 116, 133, 219, 339, 358, 391, 436], 194: [8, 33, 37, 123, 130, 179, 252, 369, 398, 404, 439, 440, 449, 463, 489, 493], 87: [8, 44, 203, 406], 186: [8, 44, 228, 248, 277, 437, 438], 132: [8, 30, 167, 177, 368, 382], 260: [8, 78, 169, 249, 306, 344, 384, 414, 457], 273: [8, 38, 118], 207: [8, 32, 55, 109, 192, 210, 278], 259: [8, 25, 26, 57, 125, 164, 185, 301, 311, 322, 458], 94: [9, 119, 198, 293], 274: [9, 25, 31, 80, 108, 175, 206, 237, 332, 419, 434], 272: [9], 295: [10, 91, 104, 180, 266, 347, 362, 414, 424, 438, 456, 458], 71: [10, 13, 31, 44, 64, 99, 104, 236, 423], 119: [11, 137, 148, 264, 352, 451, 483], 67: [12, 95, 164, 187, 274, 315, 365, 377, 465, 481], 235: [12, 61, 97, 117, 131, 209, 329, 360], 184: [13, 39, 86, 134, 166, 362], 52: [13], 106: [13, 47, 80, 94, 116, 126, 149, 199, 253, 306, 447], 11: [14, 25, 55, 57, 92, 105, 187, 253, 376, 429], 31: [14, 29, 50, 240, 250, 258, 299, 435], 179: [15, 56, 73, 125, 152, 167, 171, 180, 283, 314, 337, 498], 192: [15, 66, 169, 327], 36: [15, 39, 83, 95, 149, 151, 210, 282, 393, 443], 97: [16, 133, 254, 321, 483], 155: [16, 33, 38, 101, 363, 452, 480], 145: [16, 47, 77, 141, 143, 146, 151, 175, 193, 219, 243, 324, 353, 484, 485], 13: [17, 23, 176, 236, 488], 23: [17, 64, 67, 72, 94, 247, 493], 33: [18, 26, 49, 63, 116, 265, 325, 375], 3: [18, 451], 93: [18, 23, 30, 33, 36, 57, 60, 98, 139, 165, 309], 101: [19, 77, 109, 185, 257, 399, 432, 460], 182: [19, 380, 413], 173: [20, 23, 115, 194, 202, 257, 495], 37: [20, 91, 95, 162, 231], 49: [20, 119, 239, 370, 388], 138: [21, 153, 172, 204, 261], 4: [21, 83, 97, 307, 481], 257: [21, 99, 112, 218, 312, 482], 286: [22, 29, 61, 85, 107, 257, 272, 321, 355, 446, 495], 139: [22, 31, 43, 144, 384, 411, 445, 476], 200: [22, 135, 229, 359, 426], 262: [23, 41, 83, 115, 136, 184, 224, 356, 368, 370, 433, 446, 462, 498], 268: [23], 124: [23, 37, 75, 123, 154, 190, 264, 312, 388, 391, 463], 9: [23, 149, 275, 340], 161: [23, 24, 71, 77, 84, 149, 198, 285, 410, 455, 474], 47: [23, 46, 57, 98, 163, 201, 234, 255, 427], 251: [23, 41, 43, 185, 199, 441], 114: [23, 54, 123, 129, 208, 295, 301, 323, 356, 407, 422], 203: [23, 30, 107, 110, 140, 149, 154, 184, 267, 280, 288, 361, 365, 374, 487], 204: [24, 168, 194, 323, 396, 462, 463, 480, 484, 494], 171: [24, 168, 389, 405, 432], 299: [25, 42, 59, 75, 82, 176, 183, 189, 311, 357, 388, 459], 275: [25, 35, 42, 74, 118, 128, 161, 231, 235, 279, 402], 135: [25, 188, 442], 196: [26, 30, 33, 35, 150, 190, 268], 56: [27, 36, 63, 116, 148, 298, 445, 485, 488], 169: [27, 67, 71, 83, 291, 350], 121: [27, 50, 72, 83, 147, 222, 245, 378, 384, 392], 154: [27, 58, 59, 109, 190, 235, 377, 421, 458, 479], 261: [27, 46, 91, 118, 123, 212, 234, 322], 245: [28, 119, 142, 162, 265, 326, 403, 478], 206: [28, 30, 184, 310, 313, 330, 352, 386, 409, 429, 430, 445, 487], 144: [30, 124, 136, 153, 262, 326, 377, 402], 7: [30, 44, 58, 65, 120, 318, 331, 353, 392, 425, 442], 143: [30, 67, 75, 105, 110, 122, 145, 156], 149: [30, 45, 92, 98, 118, 273, 334, 351], 111: [30, 50, 116, 149, 236, 417, 476], 210: [32, 102, 106, 258, 333, 367, 393], 163: [32, 100, 149, 150, 218, 220, 271, 291, 311, 428, 497], 134: [33, 169, 356, 363], 226: [33, 58, 145, 163, 181, 204, 241, 300], 95: [34, 133], 64: [34, 68, 73, 83, 115, 168, 276, 327, 397, 407], 279: [34, 132, 239, 247, 324, 447, 460], 51: [35, 304], 193: [36, 48, 116, 132, 160, 277, 289, 373, 441, 499], 58: [36, 156, 277, 292, 305, 407, 450], 147: [37, 77, 143, 183, 211, 259, 294, 328, 390, 400, 447], 189: [38, 119, 182, 313, 333, 339, 492], 228: [39, 151, 394], 197: [40, 53, 84, 93, 218, 221, 306, 344, 349], 105: [40, 67, 133, 197, 209, 248, 292, 308, 312, 343, 422], 258: [40, 98, 124, 127, 229, 278, 313, 381, 389], 8: [40, 150, 245, 290, 361, 415, 422, 478], 92: [40, 71, 106, 136, 199, 239, 316, 342, 459], 175: [40, 124, 273, 294, 372, 413, 450, 451], 61: [40, 89, 138, 201, 205], 292: [40, 132, 251, 255, 268, 357, 470, 481], 104: [41, 146, 270, 373, 467], 217: [41, 140, 212, 229, 382, 412, 476], 136: [41, 44, 335, 340], 225: [42, 71, 133, 238, 307, 406], 298: [43, 86, 89, 101, 131, 182, 223, 233, 349, 369], 224: [44, 52, 88, 112, 263], 48: [44, 210, 246, 262, 435], 44: [44, 115, 172, 214, 293, 406, 491], 256: [45, 166, 206, 416, 437], 129: [46, 177], 122: [46, 58, 75, 116, 385, 424], 187: [47, 85, 146, 191, 371, 469], 246: [47, 52, 116, 176, 200, 224, 303, 334, 353, 385], 24: [48, 297], 146: [48, 58, 118, 165, 209, 355], 76: [49, 68, 87, 110, 158, 490], 16: [49, 81, 104, 111, 144, 171, 305], 264: [50, 220, 286, 329, 370], 130: [50, 55, 75, 106, 188, 275, 282, 379, 412, 450, 470, 474], 62: [51, 247, 351, 359, 455], 220: [51, 181, 186, 237], 30: [53, 56, 63, 116, 117, 122, 178, 221, 398, 455], 276: [54, 62, 101, 123, 159, 223, 254, 280, 332, 431, 441, 453, 465], 280: [56, 158, 200, 426], 212: [56, 65, 83, 152, 170, 174, 222, 232, 250, 272, 288, 302, 304, 471, 475], 46: [57, 68, 83, 135, 228, 348, 415, 471, 489], 219: [57, 67, 126, 399], 63: [57, 72, 127], 27: [57, 83, 89, 111, 141, 149, 367, 466], 231: [58, 105, 118, 131, 165, 242, 292, 387, 391, 431], 176: [58, 71, 97, 113, 256, 345, 478], 241: [58, 136, 170, 294, 310, 449], 213: [58], 150: [58, 71, 97, 120, 123, 147, 149, 177, 195, 232, 267, 319, 332, 404, 410], 290: [58, 174, 246, 418, 433], 153: [58, 149, 203, 215, 317, 366, 449, 482], 1: [59, 93, 97, 263, 269, 303, 328, 354, 358, 395, 397, 427], 168: [59, 293], 98: [59, 108, 211, 328, 417], 293: [59], 65: [60, 94, 100, 105, 149, 316, 389, 454, 490, 492], 232: [62, 146, 167], 84: [62, 85, 101, 155], 118: [62, 67, 164, 207, 410, 425, 479], 18: [64, 162, 456, 494], 248: [65, 77, 101, 178, 314, 322, 329, 471, 473], 12: [65, 67, 211, 271, 375, 383, 467], 242: [66, 103, 149, 154, 159, 201, 226, 272, 327, 354, 453, 488], 208: [66, 174, 259], 126: [66, 71, 75, 99, 159, 226, 426], 5: [67, 88, 172, 212, 440], 69: [67, 93, 223, 480], 66: [67, 101, 162, 396], 75: [67], 227: [67, 81, 83, 145, 255, 379, 430], 72: [67, 74, 149, 281, 395], 277: [67, 144, 162, 231, 279], 35: [69, 80, 93, 102, 116, 183, 278, 346, 348, 401, 420], 43: [69, 72, 148, 205, 400, 472, 477, 497], 236: [70], 271: [71, 74, 85, 103, 131, 167, 173, 266, 309], 237: [72, 89, 133, 207, 214, 256, 260, 295, 345, 448, 472], 283: [74, 77, 242, 354, 357, 442, 443, 472, 489, 493], 291: [76, 83, 90, 266, 296, 338, 394, 419, 430, 454], 29: [76, 232, 281, 299, 320, 405, 444], 100: [77, 91, 263, 284, 335, 394, 423], 158: [78, 116, 131, 148, 203, 300, 368], 22: [78, 83, 86, 95, 117, 221, 320, 395, 405], 167: [79, 286], 133: [79, 89, 142, 192, 242, 336, 380, 390], 39: [79, 98, 115, 319, 343, 434], 199: [80, 139, 154, 173, 238, 249, 256, 296, 330, 362, 386, 401, 440], 195: [81, 115, 404, 461], 215: [82, 112, 113, 130, 216, 250, 308, 383], 60: [83, 128, 216, 252, 372, 380, 496], 288: [83, 196, 499], 142: [83, 133], 28: [83, 97, 149, 215, 235, 409, 485], 102: [84], 218: [85, 157, 244, 289, 334, 392, 438, 464], 281: [86, 365], 17: [88, 154, 182, 275, 331, 360, 396], 59: [88, 92, 301, 378], 42: [89, 116, 134, 149, 160, 161, 208, 260, 262, 283, 339, 342, 439], 40: [89, 112, 189, 233, 310, 317, 437], 201: [90, 149, 161, 469], 180: [90, 179, 265, 283, 425], 140: [91, 103, 315, 318, 355, 371, 453], 25: [92, 106, 152, 234, 290, 323, 468], 151: [92, 125, 196, 280], 166: [96, 281, 331, 358, 483], 128: [96, 282, 479], 172: [100, 127, 219, 252, 386], 296: [102, 118, 258, 291, 446, 494], 181: [105, 129, 146, 149, 287], 267: [106, 344], 57: [106, 108, 170, 314, 333, 381], 282: [107, 123, 131, 154, 156, 206, 253, 393, 411, 496, 498], 156: [112, 215, 435], 174: [112, 115, 364], 152: [113, 347], 244: [114, 193, 202, 326, 401, 468], 247: [114, 133, 154, 186, 213, 243, 276, 299, 300, 341, 473], 294: [115, 118, 387, 457], 45: [115, 202, 297, 349], 285: [115, 150, 217, 227, 240, 273, 341, 484], 79: [116, 146, 188, 305], 80: [120, 121, 304, 421, 432, 452], 177: [121, 197, 225, 226, 285, 297, 400, 403, 411], 32: [122, 146, 154, 181, 227, 251, 383, 448], 82: [123, 287, 295, 412], 85: [123, 133, 159, 321], 162: [128, 376, 378, 424, 431], 117: [130, 156, 269], 41: [133, 217, 427, 486], 77: [134, 165, 261], 233: [135], 96: [138, 230, 421], 125: [139, 165], 250: [140, 141, 154, 157, 194, 259, 270, 308, 315, 420, 439], 249: [142, 175, 198, 271, 320, 367, 399, 409, 417], 108: [146, 246, 254], 222: [146, 173, 208, 397, 416, 491], 34: [146, 213, 366], 188: [149, 423], 6: [149], 209: [154, 436], 263: [157, 413], 55: [164, 418], 68: [171, 213, 220, 390], 54: [193, 491], 26: [222, 363, 428], 91: [225, 309, 464], 165: [228, 270, 274, 307, 325, 408, 415], 202: [233], 270: [237], 216: [244, 492], 127: [248], 266: [261, 298, 443], 115: [267, 290, 303, 338, 464], 238: [287, 345, 346, 347], 38: [289, 369], 240: [302, 456, 462], 103: [318, 418], 113: [337, 469], 297: [337], 109: [338], 190: [351], 278: [360], 239: [366], 10: [382], 88: [416], 78: [433], 223: [461, 486], 120: [461], 21: [468], 198: [473]}\n"
          ]
        }
      ],
      "source": [
        "# Test 2\n",
        "n2 = 500  # Number of nodes\n",
        "gamma2 = 2.5  # Power-law exponent\n",
        "kmin2 = 3  # Minimum degree\n",
        "num_hyper_edges2 = 300  # Desired number of hyper edges\n",
        "\n",
        "degrees2, hyperedge_dict2 = build_hypergraph(n2, gamma2, kmin2, num_hyper_edges2)\n",
        "H2 = hnx.Hypergraph(hyperedge_dict2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bbX083i9Htn"
      },
      "source": [
        "## Part 2: Assign Behavior Status\n",
        "NP represents the state of no protection, while P represents the state of with protection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elKpYEaU9HE1"
      },
      "outputs": [],
      "source": [
        "def assign_protection(hypergraph, fraction_protected):\n",
        "    nodes = list(hypergraph.nodes())\n",
        "    num_nodes_to_protect = int(len(nodes) * fraction_protected)\n",
        "    nodes_to_protect = random.sample(nodes, num_nodes_to_protect)\n",
        "    protection_status = {}\n",
        "\n",
        "    for node in nodes:\n",
        "        if node in nodes_to_protect:\n",
        "            protection_status[node] = \"P\"  # Protected node\n",
        "        else:\n",
        "            protection_status[node] = \"N\"  # Non-protected node\n",
        "\n",
        "    return protection_status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxZAdvJR-TXv",
        "outputId": "6237fe2b-dfc0-48f4-cfda-a8c851efcbb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'N', 30: 'P', 249: 'N', 408: 'N', 414: 'N', 18: 'N', 269: 'N', 420: 'P', 111: 'N', 1: 'N', 33: 'N', 47: 'N', 70: 'N', 94: 'N', 143: 'N', 260: 'N', 335: 'N', 5: 'N', 131: 'N', 169: 'N', 195: 'N', 50: 'N', 60: 'N', 251: 'N', 319: 'N', 3: 'N', 75: 'N', 77: 'N', 163: 'N', 241: 'N', 436: 'N', 466: 'N', 477: 'N', 54: 'N', 83: 'N', 146: 'N', 149: 'N', 160: 'N', 284: 'N', 2: 'N', 39: 'P', 122: 'N', 155: 'N', 230: 'P', 342: 'N', 457: 'P', 497: 'N', 12: 'N', 42: 'N', 115: 'N', 153: 'N', 191: 'P', 217: 'N', 240: 'N', 343: 'N', 444: 'N', 465: 'N', 11: 'N', 14: 'N', 214: 'N', 8: 'N', 23: 'N', 61: 'N', 69: 'N', 133: 'N', 196: 'N', 204: 'N', 364: 'N', 95: 'N', 189: 'N', 298: 'N', 340: 'N', 372: 'N', 454: 'P', 4: 'N', 53: 'N', 57: 'N', 85: 'N', 130: 'N', 158: 'N', 192: 'N', 225: 'N', 324: 'N', 51: 'N', 44: 'N', 166: 'N', 348: 'N', 448: 'N', 86: 'N', 134: 'N', 147: 'N', 186: 'N', 244: 'P', 325: 'P', 73: 'N', 460: 'N', 16: 'N', 17: 'N', 29: 'N', 45: 'N', 126: 'N', 129: 'N', 138: 'N', 154: 'N', 227: 'N', 316: 'N', 403: 'N', 434: 'N', 6: 'N', 58: 'N', 200: 'N', 419: 'N', 10: 'N', 82: 'N', 93: 'P', 96: 'N', 103: 'N', 207: 'N', 268: 'N', 350: 'N', 375: 'N', 429: 'N', 52: 'N', 74: 'N', 180: 'P', 205: 'N', 288: 'P', 373: 'N', 114: 'N', 121: 'N', 276: 'N', 336: 'N', 398: 'N', 97: 'N', 245: 'N', 274: 'P', 285: 'N', 330: 'N', 361: 'N', 374: 'N', 452: 'N', 482: 'N', 243: 'N', 296: 'N', 352: 'N', 381: 'N', 137: 'N', 459: 'N', 475: 'N', 490: 'N', 499: 'N', 7: 'N', 87: 'N', 116: 'N', 264: 'N', 279: 'N', 428: 'N', 178: 'N', 341: 'N', 371: 'N', 379: 'N', 76: 'N', 385: 'N', 486: 'N', 48: 'N', 81: 'P', 179: 'N', 359: 'N', 376: 'N', 470: 'N', 106: 'N', 165: 'N', 224: 'N', 302: 'N', 402: 'N', 467: 'N', 19: 'N', 28: 'N', 187: 'N', 197: 'N', 346: 'N', 487: 'N', 496: 'N', 99: 'N', 59: 'P', 317: 'N', 495: 'N', 71: 'N', 150: 'N', 216: 'N', 238: 'P', 286: 'N', 387: 'N', 474: 'N', 63: 'N', 67: 'N', 219: 'N', 339: 'N', 358: 'N', 391: 'N', 37: 'P', 123: 'N', 252: 'N', 369: 'P', 404: 'N', 439: 'P', 440: 'N', 449: 'N', 463: 'N', 489: 'N', 493: 'N', 203: 'N', 406: 'N', 228: 'N', 248: 'N', 277: 'N', 437: 'N', 438: 'N', 167: 'N', 177: 'P', 368: 'N', 382: 'N', 78: 'N', 306: 'N', 344: 'N', 384: 'N', 38: 'N', 118: 'N', 32: 'N', 55: 'N', 109: 'N', 210: 'N', 278: 'N', 25: 'N', 26: 'N', 125: 'P', 164: 'N', 185: 'N', 301: 'N', 311: 'N', 322: 'N', 458: 'N', 9: 'N', 119: 'N', 198: 'N', 293: 'N', 31: 'N', 80: 'N', 108: 'N', 175: 'N', 206: 'N', 237: 'N', 332: 'N', 91: 'N', 104: 'N', 266: 'N', 347: 'N', 362: 'N', 424: 'N', 456: 'N', 13: 'N', 64: 'N', 236: 'N', 423: 'N', 148: 'P', 451: 'N', 483: 'N', 315: 'N', 365: 'N', 377: 'N', 481: 'P', 117: 'N', 209: 'N', 329: 'P', 360: 'P', 199: 'N', 253: 'N', 447: 'N', 92: 'N', 105: 'N', 250: 'N', 258: 'N', 299: 'N', 435: 'N', 15: 'N', 56: 'P', 152: 'N', 171: 'P', 283: 'N', 314: 'N', 337: 'N', 498: 'N', 66: 'N', 327: 'N', 151: 'N', 282: 'P', 393: 'N', 443: 'N', 254: 'P', 321: 'N', 101: 'N', 363: 'P', 480: 'N', 141: 'N', 193: 'P', 353: 'N', 484: 'N', 485: 'N', 176: 'N', 488: 'N', 72: 'N', 247: 'N', 49: 'N', 265: 'N', 36: 'P', 98: 'N', 139: 'N', 309: 'N', 257: 'P', 399: 'P', 432: 'N', 380: 'N', 413: 'P', 20: 'N', 194: 'N', 202: 'N', 162: 'N', 231: 'N', 239: 'N', 370: 'N', 388: 'N', 21: 'N', 172: 'N', 261: 'N', 307: 'N', 112: 'N', 218: 'N', 312: 'N', 22: 'N', 107: 'N', 272: 'N', 355: 'N', 446: 'N', 43: 'N', 144: 'N', 411: 'N', 445: 'N', 476: 'N', 135: 'N', 229: 'N', 426: 'N', 41: 'N', 136: 'N', 184: 'N', 356: 'N', 433: 'N', 462: 'N', 190: 'N', 275: 'N', 24: 'N', 84: 'N', 410: 'N', 455: 'N', 46: 'N', 201: 'N', 234: 'N', 255: 'N', 427: 'N', 441: 'N', 208: 'N', 295: 'N', 323: 'N', 407: 'P', 422: 'N', 110: 'N', 140: 'N', 267: 'P', 280: 'N', 168: 'N', 396: 'N', 494: 'N', 389: 'N', 405: 'N', 183: 'N', 357: 'P', 35: 'P', 128: 'N', 161: 'N', 235: 'N', 188: 'N', 442: 'N', 27: 'N', 291: 'N', 222: 'N', 378: 'P', 392: 'N', 421: 'N', 479: 'N', 212: 'N', 142: 'N', 326: 'N', 478: 'N', 310: 'N', 313: 'N', 386: 'N', 409: 'N', 430: 'P', 124: 'N', 262: 'N', 65: 'N', 120: 'N', 318: 'N', 331: 'N', 425: 'N', 145: 'N', 156: 'N', 273: 'N', 334: 'N', 351: 'P', 417: 'N', 102: 'N', 333: 'N', 367: 'N', 100: 'N', 220: 'P', 271: 'N', 181: 'N', 300: 'N', 34: 'N', 68: 'N', 397: 'N', 132: 'N', 304: 'N', 289: 'N', 292: 'N', 305: 'N', 450: 'N', 211: 'P', 259: 'N', 294: 'N', 328: 'N', 390: 'N', 400: 'N', 182: 'N', 492: 'N', 394: 'P', 40: 'N', 221: 'N', 349: 'N', 308: 'N', 127: 'N', 290: 'N', 415: 'N', 89: 'N', 270: 'N', 412: 'N', 223: 'N', 233: 'N', 88: 'N', 263: 'N', 246: 'N', 491: 'P', 416: 'N', 469: 'N', 303: 'N', 297: 'N', 62: 'N', 159: 'N', 431: 'N', 453: 'N', 170: 'N', 174: 'N', 232: 'N', 471: 'P', 242: 'N', 113: 'N', 256: 'N', 345: 'N', 418: 'N', 215: 'N', 366: 'N', 354: 'N', 395: 'N', 473: 'P', 383: 'N', 226: 'P', 281: 'N', 401: 'N', 472: 'N', 173: 'P', 90: 'N', 338: 'N', 320: 'N', 79: 'N', 461: 'N', 157: 'N', 464: 'N', 468: 'N', 287: 'N', 213: 'N'}\n"
          ]
        }
      ],
      "source": [
        "# Test:\n",
        "fraction_protected = 0.1\n",
        "protection_status_dict = assign_protection(H2, fraction_protected)\n",
        "print(protection_status_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F71C7Qfa_b9I"
      },
      "source": [
        "\n",
        "## Part 3: Assign Threshold\n",
        "The following steps assigns a threshold value to each node in the network. The threshold follows a uniform or normal distribution with predefined mean (mu) and standard deviation (sigma)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ky4HFlQR_jBY"
      },
      "outputs": [],
      "source": [
        "# Defines the parameters to be used\n",
        "mu = 0.1\n",
        "sigma = 0.05\n",
        "\n",
        "def assign_thresholds(hypergraph, mu, sigma):\n",
        "    NV = hypergraph.order()\n",
        "    Ltre = {}\n",
        "\n",
        "    for node in hypergraph.nodes():\n",
        "\n",
        "          while True:\n",
        "              threshold = random.gauss(mu, sigma)\n",
        "              if 0 < threshold < 1:\n",
        "                  break\n",
        "          Ltre[node] = threshold\n",
        "\n",
        "    return Ltre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ11eyyS_o1O",
        "outputId": "349b15e5-b1df-408e-86be-6fc9a11b8a25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold List for Nodes:  {0: 0.037946129250606676, 30: 0.18499315755381382, 249: 0.1433089780797135, 408: 0.027715512748661783, 414: 0.07392474135013101, 18: 0.12022684148561694, 269: 0.0258398084144401, 420: 0.013734359826089143, 111: 0.059035458292786266, 1: 0.20248762815755927, 33: 0.05355493369567456, 47: 0.1271675899330481, 70: 0.061437147617575426, 94: 0.03310120697967893, 143: 0.06638414410474872, 260: 0.20217655174348448, 335: 0.013811419778586728, 5: 0.09836567882369622, 131: 0.029671868695594447, 169: 0.05906845674846044, 195: 0.13209764245275996, 50: 0.15895723818304744, 60: 0.05383833861951939, 251: 0.1254905088995319, 319: 0.06036357396778941, 3: 0.08303412907924551, 75: 0.11468315691880118, 77: 0.1418490256129436, 163: 0.10109697191070005, 241: 0.1019432193702961, 436: 0.11757613147082402, 466: 0.09439877652305373, 477: 0.19456335300096234, 54: 0.10761119434635508, 83: 0.09146150374963374, 146: 0.13776751018159256, 149: 0.13164518067674452, 160: 0.12608567872109894, 284: 0.03293685804416213, 2: 0.10935976025451159, 39: 0.1793470279681566, 122: 0.04031583953780929, 155: 0.10977320995356371, 230: 0.09229734148551294, 342: 0.05604105170263896, 457: 0.1702759438067884, 497: 0.15802449023338908, 12: 0.07250653781332446, 42: 0.126206628433037, 115: 0.05203192475315107, 153: 0.1944251976510757, 191: 0.022213631416311677, 217: 0.08646869671021418, 240: 0.011972917334988217, 343: 0.1110696572857341, 444: 0.12036862390508696, 465: 0.08283633497893161, 11: 0.05706184986246608, 14: 0.09096117132737716, 214: 0.12521774361108762, 8: 0.02660430054538064, 23: 0.2059025130919344, 61: 0.03828304119103986, 69: 0.09045026023963064, 133: 0.14799111754463645, 196: 0.04091670790139156, 204: 0.06295167299981351, 364: 0.1554595194884912, 95: 0.015049972468625841, 189: 0.1345240392115022, 298: 0.05520585295611527, 340: 0.18538608074781265, 372: 0.08970386446544952, 454: 0.12701096826610714, 4: 0.11654736132865735, 53: 0.16182085948979585, 57: 0.11093932940239504, 85: 0.11425136674826336, 130: 0.07712351965328051, 158: 0.10362654318046033, 192: 0.2523376306612213, 225: 0.06701737044281936, 324: 0.043818397459309204, 51: 0.19800775256563966, 44: 0.1720186216977811, 166: 0.053145439763577954, 348: 0.05747377824311656, 448: 0.11856278826611273, 86: 0.039728340589275914, 134: 0.08966917660602723, 147: 0.09558630646850849, 186: 0.07607909481161859, 244: 0.1307317163709609, 325: 0.15750174354303542, 73: 0.1580402270990763, 460: 0.03358929185640408, 16: 0.13227855704217217, 17: 0.09415837553205665, 29: 0.1021315735510067, 45: 0.08947902739686135, 126: 0.1300618883767362, 129: 0.09415500752837065, 138: 0.07542495000748206, 154: 0.19515194125016133, 227: 0.144670671576213, 316: 0.17807268322595285, 403: 0.0692432270153418, 434: 0.0890226593177149, 6: 0.13915213610370178, 58: 0.15088547513358772, 200: 0.05306502963676071, 419: 0.14684585851871337, 10: 0.053895836158225956, 82: 0.07711648147951958, 93: 0.06022195968642474, 96: 0.04436552453423747, 103: 0.1534816708963128, 207: 0.08980086882031653, 268: 0.030404438680259258, 350: 0.0566087732351278, 375: 0.0439467775429783, 429: 0.08275229854195726, 52: 0.10168992504931501, 74: 0.0478648713336149, 180: 0.17560794839483246, 205: 0.0894383017945811, 288: 0.13501126119169374, 373: 0.02443214439480533, 114: 0.13432893197220938, 121: 0.15518570626704964, 276: 0.18792253015250204, 336: 0.0701592798515924, 398: 0.06416948294674585, 97: 0.11513193317707304, 245: 0.04549552348490798, 274: 0.06639714621051965, 285: 0.058350906894830364, 330: 0.022428987478509424, 361: 0.17084562387045932, 374: 0.10972898331587813, 452: 0.08059728930834337, 482: 0.1251388524336641, 243: 0.02833351608565915, 296: 0.10297663976009258, 352: 0.05613297318984511, 381: 0.10473636135517025, 137: 0.08385607392233456, 459: 0.08992629637979192, 475: 0.13798225700921898, 490: 0.12093973125437513, 499: 0.1001631043884625, 7: 0.09941060768101234, 87: 0.09327193136189815, 116: 0.11632427819015786, 264: 0.11462624612287661, 279: 0.14733514368656928, 428: 0.039943525344946135, 178: 0.029399126742942303, 341: 0.21590249104252365, 371: 0.06176736737738461, 379: 0.0953986858695901, 76: 0.1275059318406768, 385: 0.05441429166702557, 486: 0.1189516443476939, 48: 0.1411679742107804, 81: 0.08708141999641286, 179: 0.06835959650436133, 359: 0.18831602014771104, 376: 0.1336569016577615, 470: 0.10562791916676842, 106: 0.14488883797550078, 165: 0.07818728433550204, 224: 0.20144607927533242, 302: 0.005907082998273125, 402: 0.15748738167902818, 467: 0.09382841798808365, 19: 0.1078576712566968, 28: 0.07744038685471209, 187: 0.1362632501102183, 197: 0.08698386346645959, 346: 0.12026405760805071, 487: 0.1782857960478369, 496: 0.11715968385302394, 99: 0.054008297195783345, 59: 0.08564285002947208, 317: 0.1394876019891762, 495: 0.08108393032173605, 71: 0.06461294086076455, 150: 0.11372080028852244, 216: 0.03821360264339411, 238: 0.053998427895260194, 286: 0.08774776045407444, 387: 0.18106812770462608, 474: 0.06377667045609148, 63: 0.11732219155069051, 67: 0.11017288283175042, 219: 0.09718916443719054, 339: 0.11684649277469206, 358: 0.0443876020727808, 391: 0.0975602978006548, 37: 0.11433354900556864, 123: 0.03655652790509392, 252: 0.020255388882000916, 369: 0.1824547619667599, 404: 0.07808268864619969, 439: 0.12705875417261317, 440: 0.07760817791539865, 449: 0.11958019452185431, 463: 0.146584245923567, 489: 0.14790644360641114, 493: 0.1309674634540409, 203: 0.13879962633073087, 406: 0.04434415635876785, 228: 0.1063159459849677, 248: 0.050335012558690995, 277: 0.11469006517398284, 437: 0.18098421909944312, 438: 0.025148536702667618, 167: 0.049394270554359646, 177: 0.0583464669841888, 368: 0.11534631213888244, 382: 0.09198914679015376, 78: 0.08299781077762151, 306: 0.15025547640053957, 344: 0.11396111922033923, 384: 0.17216551919294998, 38: 0.0658503235260594, 118: 0.12575106202405611, 32: 0.1544608063581293, 55: 0.11336417386405286, 109: 0.07824579591049566, 210: 0.04004515092924315, 278: 0.14857228122264343, 25: 0.12561478581120497, 26: 0.08785992150627653, 125: 0.07421441936473627, 164: 0.09483640237914974, 185: 0.08610109886464877, 301: 0.09193869262802268, 311: 0.10449917927792796, 322: 0.07402915998124075, 458: 0.10205693386129121, 9: 0.0875945766622582, 119: 0.11909660577727477, 198: 0.07646958235305965, 293: 0.04178706761015336, 31: 0.012607418773063345, 80: 0.047943560104384164, 108: 0.18410423518525154, 175: 0.080833876290566, 206: 0.1379457218469182, 237: 0.10056050985271163, 332: 0.10795831477174378, 91: 0.07260419239492687, 104: 0.10262236665295049, 266: 0.07373796095424404, 347: 0.1385110314253606, 362: 0.10043525865343947, 424: 0.12052022326757161, 456: 0.1488811380731471, 13: 0.043445170393274835, 64: 0.15226819943401534, 236: 0.03546578048864024, 423: 0.005905685781958492, 148: 0.11611674985841311, 451: 0.04951173862983668, 483: 0.027751225164189347, 315: 0.0710294852451004, 365: 0.042677779507818384, 377: 0.12949287104552473, 481: 0.11221283904064291, 117: 0.1370251872001322, 209: 0.07390654397562559, 329: 0.032639757359763016, 360: 0.08771974971365207, 199: 0.13493011447487877, 253: 0.1033111677076136, 447: 0.1952563702807765, 92: 0.14273546877332796, 105: 0.0828942263068304, 250: 0.10048214174338968, 258: 0.23835470302681602, 299: 0.0811751294341727, 435: 0.14992543855815701, 15: 0.10043354416928661, 56: 0.19839884434209415, 152: 0.1456533813492267, 171: 0.09139804305718946, 283: 0.14090651044975108, 314: 0.09135735798220955, 337: 0.08509135079435431, 498: 0.09323889185256119, 66: 0.07969457121936596, 327: 0.04737258773537313, 151: 0.13574228990110684, 282: 0.09304699047481611, 393: 0.10638891230404898, 443: 0.09866140557743903, 254: 0.0780836897367218, 321: 0.041268058392686026, 101: 0.004470627901385152, 363: 0.120084438295851, 480: 0.12289693047824678, 141: 0.09479824769070351, 193: 0.0754955238082641, 353: 0.05025948786604223, 484: 0.10178972635653524, 485: 0.15986524122222584, 176: 0.021394712818500444, 488: 0.05048994715070215, 72: 0.11698326590305258, 247: 0.09364528728866003, 49: 0.10834010722659435, 265: 0.11835062576274505, 36: 0.020644827116974088, 98: 0.19790535314639585, 139: 0.1779277592194831, 309: 0.1378434581104572, 257: 0.08902189680977154, 399: 0.20361484678161557, 432: 0.12783036320504648, 380: 0.10441353874871794, 413: 0.06721328299992799, 20: 0.12813450873560567, 194: 0.08942966189958305, 202: 0.16561986696529418, 162: 0.09838578995758349, 231: 0.11639327961593442, 239: 0.1348407495289349, 370: 0.13399403264998977, 388: 0.08969157713219361, 21: 0.1385098282713182, 172: 0.017851339596134885, 261: 0.06992301137705728, 307: 0.09676311498637055, 112: 0.12115000645859597, 218: 0.06419895147060181, 312: 0.138292592283426, 22: 0.05110813047680149, 107: 0.15981159754908625, 272: 0.1839088639503062, 355: 0.1016345291792355, 446: 0.1260522350473301, 43: 0.06856385239827414, 144: 0.12835973304800494, 411: 0.10270590752201299, 445: 0.21219675288536968, 476: 0.1314642555350208, 135: 0.12169215489302287, 229: 0.1493703807192818, 426: 0.0966756769636501, 41: 0.10273256696842446, 136: 0.21299286023402786, 184: 0.025920111537191703, 356: 0.07957091035956168, 433: 0.13287521059951216, 462: 0.09056591034906866, 190: 0.14727212933247497, 275: 0.15112903708852096, 24: 0.0908764629541427, 84: 0.06775642369793744, 410: 0.020181611944352487, 455: 0.15505055029200748, 46: 0.08061942840429748, 201: 0.09828759573758164, 234: 0.16435399202908252, 255: 0.020713492501876013, 427: 0.062304714755769375, 441: 0.1577749487286486, 208: 0.06183842853494226, 295: 0.11627365669481148, 323: 0.138654186493413, 407: 0.0843575962328422, 422: 0.07463965755824117, 110: 0.013974329756849119, 140: 0.0762778159097855, 267: 0.03407847987684352, 280: 0.14032284453385022, 168: 0.19187057945457942, 396: 0.22047310791296112, 494: 0.07256812813326297, 389: 0.07303386304369702, 405: 0.051025781567366334, 183: 0.1957569809275778, 357: 0.10402745469895353, 35: 0.1350616367611708, 128: 0.12749188429238223, 161: 0.1489373146867765, 235: 0.048072270757648396, 188: 0.007020125035902075, 442: 0.020875774074158776, 27: 0.14600029828975586, 291: 0.01536887623327085, 222: 0.10345341840902403, 378: 0.17990459196436354, 392: 0.09225912720340383, 421: 0.18015826057297113, 479: 0.061424954697942014, 212: 0.08293919029247243, 142: 0.15300309344330432, 326: 0.03835772728172674, 478: 0.08918833958689609, 310: 0.1094559288962416, 313: 0.14192249895255035, 386: 0.05647966814955402, 409: 0.10675210003697712, 430: 0.20385779372538382, 124: 0.16167487915120332, 262: 0.18643257236151248, 65: 0.09801392925706795, 120: 0.15273499461197854, 318: 0.11777326051839733, 331: 0.10525789902983511, 425: 0.10188004034477305, 145: 0.003656030184296971, 156: 0.20112282496642164, 273: 0.14147995923727336, 334: 0.11479610768927141, 351: 0.19231640933826816, 417: 0.10490404880017996, 102: 0.0999305521976742, 333: 0.010666333289833518, 367: 0.09737730209411895, 100: 0.015584037997810052, 220: 0.1344547219118132, 271: 0.16414760727371686, 181: 0.023460594436388107, 300: 0.09015540288485104, 34: 0.12054579698695471, 68: 0.09068289620732699, 397: 0.07053630161707139, 132: 0.05684942391806533, 304: 0.04606003779402799, 289: 0.07361345483774533, 292: 0.08825707496889264, 305: 0.09176446321066738, 450: 0.028954598646507956, 211: 0.00943498433671977, 259: 0.020150043506993745, 294: 0.028509792067781536, 328: 0.03163319369732068, 390: 0.12349201435117768, 400: 0.07845272301119864, 182: 0.1370832194487934, 492: 0.0439369977806156, 394: 0.2031050117173975, 40: 0.11548989459220928, 221: 0.055077825662053666, 349: 0.017665007726845566, 308: 0.09525912363990385, 127: 0.09989889395939776, 290: 0.10841851553628012, 415: 0.10173248098189396, 89: 0.2071056558308543, 270: 0.02115560306146215, 412: 0.04246270078007535, 223: 0.06993191123220735, 233: 0.1372467873385398, 88: 0.013758250818954015, 263: 0.09223770703135098, 246: 0.09130366093878282, 491: 0.10885741366991554, 416: 0.12564161456110878, 469: 0.1318772543677104, 303: 0.14525772321542552, 297: 0.20533587467905517, 62: 0.13641892382169546, 159: 0.08642041375008323, 431: 0.14642060666279727, 453: 0.12135010111326912, 170: 0.09726431787159766, 174: 0.138188038403182, 232: 0.09827172104752967, 471: 0.11702698066892918, 242: 0.001645232676817182, 113: 0.06846147802984619, 256: 0.09721540376463508, 345: 0.13252907642228637, 418: 0.08444333472051539, 215: 0.07537251946040066, 366: 0.13236358127855782, 354: 0.13082698684620014, 395: 0.09935894364498542, 473: 0.07760013586413696, 383: 0.10063388283848754, 226: 0.13566750355160906, 281: 0.0874462721377701, 401: 0.162136950732321, 472: 0.05300444863128024, 173: 0.04979644620832239, 90: 0.027130281804774878, 338: 0.19150719781499867, 320: 0.11433736300271169, 79: 0.11603451437111485, 461: 0.10290164586798634, 157: 0.09866392208534373, 464: 0.05340622696341696, 468: 0.012086938608224879, 287: 0.0004645367961888802, 213: 0.019406253602271717}\n"
          ]
        }
      ],
      "source": [
        "Ltre2 = assign_thresholds(H2, mu, sigma)\n",
        "\n",
        "print(\"Threshold List for Nodes: \", Ltre2 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSmz7Gj6AA9m"
      },
      "source": [
        "# Part 4: The ICE Model (The Information Cognition Epidemics Model)\n",
        "## Information Layer\n",
        "The misinformation spread occurs on a hyperedge network involving group spreading. The three stages are U(unaware), G(gossip/spreader), and C(stifler/corrected).  \n",
        "\n",
        "## Cognition Layer\n",
        "In the cognitive behavioral layer, P is protected, and N is not protected. The rate of transition from state P to N, p, depends on the information layer. The rate from NP to P is 1-p. The transition rate of a node is also affected by the number of active spreader/stiflers. The bigger number of active neighbors, the faster the rate. Another way behavior may change is based on the fraction of protected neighbors.\n",
        "\n",
        "## Epidemics Layer\n",
        "In the epidemics layer, the possible disease states are S(susceptible), I(infected), and R(recovered). The illness spreading is pairwise. The disease propagation rate depends on the fraction of protected individuals $\\rho_P$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_NnnBI-BZpo",
        "outputId": "68accbff-4930-4d93-e327-007434332315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Degree Sequence:  [3, 5, 3, 4, 7, 3, 4, 6, 8, 9, 5, 3, 6, 7, 5, 3, 7, 4, 3, 4, 6, 8, 6, 3, 3, 4, 5, 3, 5, 6, 8, 3, 3, 4, 14, 8, 4, 5, 7, 13, 3, 3, 4, 6, 3, 7, 3, 4, 5, 3, 6, 4, 8, 5, 3, 3, 3, 6, 14, 3, 3, 3, 6, 4, 3, 3, 6, 3, 3, 3, 3, 3, 4, 3, 7, 3, 3, 3, 10, 6, 10, 4, 3, 5, 4, 8, 11, 4, 5, 3, 3, 3, 3, 4, 3, 4, 5, 3, 5, 3, 3, 3, 4, 4, 5, 4, 7, 3, 6, 3, 3, 3, 4, 6, 8, 5, 3, 6, 4, 3, 8, 3, 7, 8, 3, 3, 6, 7, 3, 3, 4, 5, 3, 3, 4, 4, 7, 3, 4, 3, 5, 3, 8, 3, 9, 8, 3, 3, 7, 3, 7, 7, 7, 3, 4, 7, 4, 5, 3, 3, 4, 3, 20, 6, 3, 4, 4, 5, 4, 6, 3, 3, 3, 3, 5, 3, 5, 3, 5, 7, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
            "Hyper Edge Sizes:  [39, 15, 8, 4, 40, 7, 28, 21, 10, 31, 28, 34, 37, 16, 6, 17, 25, 23, 8, 11, 40, 31, 15, 8, 5, 36, 17, 13, 25, 41, 11, 40, 34, 17, 39, 32, 40, 15, 13, 24, 18, 5, 33, 10, 28, 28, 28, 23, 5, 30, 31, 32, 19, 35, 10, 10, 4, 3, 38, 27, 8, 13, 40, 19, 41, 5, 5, 24, 16, 20, 5, 24, 21, 27, 40, 16, 16, 4, 17, 25, 28, 15, 15, 28, 36, 38, 18, 20, 24, 36, 23, 15, 39, 15, 32, 38, 40, 18, 22, 34, 25, 7, 4, 17, 4, 22, 11, 24, 16, 33, 33, 32, 3, 40, 2, 41, 20, 35, 30, 38, 27, 19, 38, 14, 29, 31, 8, 35, 3, 4, 42, 7, 29, 16, 35, 17, 5, 37, 33, 20, 17, 10, 14, 29, 22, 4, 19, 30, 6, 31, 11, 26, 38, 24, 6, 8, 15, 11, 21, 9, 34, 14, 42, 23, 19, 26, 29, 4, 13, 33, 22, 22, 27, 35, 39, 22, 3, 32, 30, 38, 20, 23, 42, 7, 24, 30, 37, 12, 30, 36, 33, 40, 21, 34, 8, 19, 12, 20, 3, 10, 36, 11, 24, 16, 26, 32, 14, 15, 20, 26, 10, 15, 20, 37, 18, 5, 16, 19, 11, 8, 2, 34, 8, 19, 26, 39, 41, 7, 16, 32, 11, 5, 9, 7, 37, 10, 22, 14, 16, 12, 26, 17, 35, 37, 42, 14, 27, 12, 3, 39, 33, 11, 32, 13, 22, 32, 29, 24, 26, 3, 31, 36, 10, 12, 26, 15, 35, 28, 40, 25, 39, 10, 12, 25, 18, 8, 5, 40, 34, 26, 13, 2, 3, 27, 17, 5, 26, 30, 37, 2, 35, 23, 18, 8, 10, 19, 11, 17, 40, 19, 8, 11, 10, 18, 20, 2, 25, 29, 26, 8, 15, 29, 3, 12, 9, 7, 3, 35, 40, 19, 3, 14, 22, 28, 37, 21, 33, 42, 19, 9, 13, 10, 29, 24, 27, 11, 16, 39, 24, 2, 21, 6, 31, 31, 11, 5, 42, 13, 8, 13, 39, 34, 17, 38, 42, 26, 24, 3, 2, 33, 41, 29, 24, 25, 9, 41, 2, 11, 2, 23, 6, 6, 33, 33, 16, 6, 25, 31, 36, 37, 2, 17, 36, 23, 23, 24, 10, 38, 31, 8, 21, 40, 31, 13, 30, 39, 5, 39, 25, 41, 23, 35, 25, 21, 38, 37, 34, 8, 5, 40, 26, 36, 22, 24, 20, 11, 38, 35, 39, 9, 2, 32, 8, 31, 8, 18, 23, 30, 29, 12, 32, 4, 2, 40, 18, 40, 36, 32, 5, 41, 21, 6, 5, 5, 34, 11, 3, 34, 31, 36]\n",
            "Hypergraph Dictionary:  {226: [0, 114, 135, 145, 151, 307, 333, 357, 396], 369: [0, 57, 444, 489], 209: [0, 79, 126, 221, 319, 442, 492], 401: [1, 15, 35, 43, 110, 398], 26: [1, 6, 80, 282, 371, 432], 144: [1, 179], 410: [1, 35, 52, 58, 84, 86, 115, 123, 272, 301, 313], 346: [1, 49, 62, 195, 327, 399, 435, 493], 179: [2, 74, 114, 117, 127, 171, 230, 361], 165: [2, 91, 143, 150, 312, 383], 224: [2, 35, 122, 167, 240], 249: [3, 136, 201, 270, 292, 316, 349, 363, 400], 10: [3, 98, 155, 213, 279, 482, 497], 94: [3, 7, 130, 163, 210, 331, 387, 475, 494], 36: [3, 17, 129, 304, 402, 497], 240: [4, 9, 108, 119, 406, 417], 427: [4, 82, 98, 133, 141, 183, 284], 86: [4, 78, 125], 118: [4, 36, 79, 187, 190, 281, 448], 387: [4, 58, 113, 169, 412], 50: [4, 53, 116, 428, 472], 229: [4, 229, 245, 421], 110: [5, 39, 80, 86, 157, 258, 314, 358], 11: [5, 39, 89, 99, 270, 286, 438, 478], 349: [5, 66, 86, 321], 264: [6, 210, 449], 89: [6, 112, 123, 252, 454], 31: [6, 19, 35, 41, 145, 184, 213, 255, 336, 379, 478], 42: [7, 38, 78, 217, 253, 339, 405, 409, 440], 332: [7, 114, 222, 240, 348, 360, 421, 449, 485, 499], 245: [7], 51: [7, 174, 298, 317], 169: [7, 12, 114, 190, 215, 259, 278, 434, 472], 382: [8, 78, 299, 395], 360: [8, 45, 71, 205, 238, 299, 359, 450, 479], 379: [8, 118, 150, 268, 300, 307, 373, 401, 474, 491], 100: [8, 48, 160, 163, 194, 367], 385: [8, 13, 75, 107, 148, 206, 231, 403, 469], 261: [8, 121, 141, 194, 227, 264, 384, 390, 488], 188: [8, 88, 120, 151, 169, 448], 234: [8, 48, 88, 126, 210, 248, 301, 352, 382, 459], 278: [9, 52, 137, 147, 330, 337, 346, 350, 414], 416: [9, 80, 120, 310, 314, 368, 446, 498], 378: [9, 14, 16, 25, 233, 314], 85: [9, 71, 78, 135, 256, 306, 378], 20: [9, 52, 96, 172, 283, 311, 318, 321], 439: [9, 36, 50, 79, 102, 144, 163, 176, 197, 221, 340, 361, 466, 491], 59: [9, 49, 55, 183, 479], 58: [9, 30, 39, 68, 169, 281, 327, 418, 457, 464], 300: [10, 164], 163: [10, 134, 285, 290, 476], 0: [10, 17, 21, 56, 96, 162, 192, 247, 486], 437: [10, 87, 109, 114, 147, 312, 400, 430], 221: [10, 13, 162], 325: [11, 27, 42, 209, 325], 160: [11, 267, 365], 398: [11, 47, 63, 150, 300, 486], 87: [12, 70, 122, 207], 125: [12, 353, 398], 406: [12, 13, 30, 88, 135, 193, 262, 289], 124: [12, 34, 78, 122, 285, 381], 205: [12, 120, 293], 153: [13, 276, 392], 277: [13, 34, 39, 65, 79, 127, 212, 218, 298, 459, 481], 164: [13, 45, 175, 261, 313, 320], 353: [13, 39, 45, 140, 178, 251, 303, 476], 433: [14, 148, 219, 264, 471, 491], 192: [14, 39, 109, 116, 151, 155, 200, 230], 411: [14, 85, 174, 394, 445, 493, 496], 372: [14, 80, 145, 150, 174, 179, 200, 233, 262, 396], 318: [15, 61, 113, 227, 291, 309, 328, 422, 463], 6: [15, 51, 104, 107, 223, 266, 284, 358, 374, 381, 403], 72: [16], 423: [16, 177, 290, 294, 462], 235: [16, 389], 444: [16, 31, 100, 133, 134, 334, 335, 344], 35: [16, 81, 156, 223, 236, 431, 454, 480], 208: [16, 203, 292, 299], 14: [17, 120], 436: [17, 164, 165, 202, 237, 277], 140: [18, 258], 176: [18], 113: [18, 30, 39, 49, 106], 137: [19, 29, 80, 86, 91, 97, 154, 214, 409, 414, 471], 250: [19, 52, 440], 322: [19, 45, 106, 212, 395, 464], 96: [20, 40, 123, 126, 259, 267, 293, 305, 333, 419, 426], 362: [20, 56, 168, 222, 359], 273: [20, 58, 68, 177, 179, 266], 69: [20, 108, 194, 378], 377: [20, 34, 50, 156, 287, 297, 337], 288: [20, 62, 63, 94, 125, 278, 457], 200: [21, 130, 153, 162, 250, 286, 328, 347, 372], 151: [21, 197, 265], 397: [21, 103, 191, 222, 246, 282, 366, 401, 404], 146: [21, 216, 371, 477], 269: [21, 35, 60, 85, 142, 219], 383: [21, 235], 392: [21, 93, 296, 447], 279: [22, 162, 336, 467, 494], 189: [22, 113, 141, 252, 420, 456], 92: [22, 71, 155, 229, 268, 315, 408, 478], 214: [22, 146, 181, 350, 405], 178: [22, 58, 109, 112, 144, 186, 226, 272], 403: [22, 174], 65: [23, 101, 391], 225: [23, 106, 127, 139, 142, 149, 161, 199, 207, 315, 340], 232: [23, 53, 96, 410], 158: [24, 162, 165, 414], 9: [24, 91, 129, 264, 269], 83: [24, 32, 34, 162, 385, 411], 172: [25, 69, 78, 136, 150], 308: [25, 69, 192, 465, 481], 114: [25], 404: [26, 75, 117, 146, 434], 99: [26, 57, 132, 155, 165, 322, 369], 326: [26, 82, 92, 93, 121, 144], 343: [26, 62, 107, 152, 201], 95: [26, 52, 97, 170, 208, 263, 395], 196: [27, 156], 40: [27, 67, 98, 120], 156: [28, 158], 421: [28, 78, 114, 130, 362, 366, 423], 418: [28, 36, 326, 441], 193: [28, 32, 181, 199, 260, 436, 497], 88: [28, 34, 52, 150, 157], 213: [29, 167, 169, 224, 250, 254, 442], 47: [29, 43], 330: [29, 73, 122, 203, 357], 67: [29, 103, 152, 162, 168, 193, 265, 434], 244: [29, 34, 41, 70, 77, 189, 195, 216, 353, 482], 327: [30, 96, 367, 369, 407, 421], 276: [30, 332], 142: [30, 209], 46: [30, 108, 123, 140, 232, 292, 404], 12: [30, 33, 108, 162, 307, 316, 442, 468, 488], 388: [31, 98, 111, 179, 211, 265, 279, 345, 487], 49: [31, 54, 101, 128, 201, 431, 435, 455, 487], 191: [32, 48, 90, 136, 196, 219, 346, 398, 474], 173: [33, 126, 146, 152, 173, 244, 246, 253, 260, 289, 449], 121: [33, 88, 134, 297, 340, 453], 323: [33, 165, 261, 326, 339], 76: [34, 430], 262: [34, 160, 324], 43: [34, 117, 137, 175, 267, 347], 64: [34, 38, 43, 44, 288, 303, 318, 344, 363, 375, 379, 415], 405: [34, 90, 157, 271, 433], 28: [34, 86, 332, 372, 394], 197: [34, 44, 87, 105], 177: [34, 73, 162, 163, 288, 416, 464], 333: [35, 96, 128, 244, 249, 275], 337: [35, 38, 98, 105, 353, 403, 496], 162: [35, 57, 108, 155, 304, 345, 350, 374, 422, 486], 117: [36, 154, 214, 368, 425, 477], 45: [37, 47, 162, 166, 177, 188, 254, 275, 334], 25: [37, 78, 142, 176, 407, 441, 450], 147: [37, 70, 83, 310, 404, 447, 452, 466], 228: [37, 38, 145, 160, 162, 215], 356: [37, 58, 335, 351], 115: [38, 230, 234, 406, 420, 424, 427], 417: [38, 59, 76, 95, 138, 162], 93: [38, 126, 127], 292: [39, 136, 302, 430], 134: [39, 72, 83, 113, 489], 428: [39, 102, 126, 324, 338, 405], 71: [39, 65, 115, 191, 310, 435], 407: [39, 86], 138: [39, 138, 311, 474], 431: [40], 445: [40, 290, 323, 446, 485], 430: [41, 184, 225, 296, 439], 130: [42, 123, 184, 238, 263, 308, 481, 490], 30: [42, 85, 324, 393], 152: [42, 117, 128, 148, 156, 256, 323, 429, 440], 297: [43, 54, 92, 381], 180: [43, 74, 451], 290: [43, 57, 93, 138, 187, 263, 273, 386], 361: [44, 436], 284: [45, 300, 346, 364], 365: [45, 73, 81, 110, 155, 198, 208, 296, 484], 143: [45, 82, 85, 149, 327], 29: [46, 58, 145, 384, 495], 347: [46], 283: [46, 119, 373, 411, 423, 443], 181: [47, 79, 140, 162, 317, 412], 319: [47, 161, 224, 447, 484], 412: [48, 50, 64, 104, 363, 408, 420], 268: [48, 218, 228, 238, 387, 397, 424, 431], 338: [50, 106, 112, 452], 320: [50, 271], 266: [50, 80, 105, 138, 163, 190, 237, 317, 351, 402, 471], 201: [51, 409], 442: [51], 394: [51, 154, 240, 308, 309, 362, 459], 242: [52, 106, 143, 144, 151, 157, 274, 329, 402, 428, 483], 17: [52, 241], 190: [53, 74, 85, 120, 132, 148, 202, 228, 498], 39: [53, 66, 273], 272: [53, 62, 152, 245], 342: [54, 68, 72, 140, 167, 189, 225, 226, 272, 384, 422, 463], 161: [55, 441, 476], 98: [55, 234, 329], 424: [56, 103, 282, 358], 107: [57, 142], 53: [57, 120, 205, 304, 472], 122: [58, 308, 385, 415], 341: [58, 367, 427], 4: [58, 111, 124, 196, 251, 437, 493], 175: [58, 306, 388, 455], 74: [58, 85, 99, 114, 294, 370, 385, 399, 417, 436, 484], 220: [58], 184: [58, 150, 187, 188], 298: [58, 94, 339, 391, 480], 275: [59], 390: [59], 434: [60, 74, 80, 198], 257: [60, 64, 116, 132, 255, 388, 451, 467, 479], 54: [61, 262], 212: [61, 241, 364], 324: [62, 162, 171, 199], 295: [62, 247, 426, 499], 109: [63, 104, 108, 221, 269, 386, 399], 202: [63, 77], 351: [64, 92, 131, 315, 489], 381: [65, 391], 127: [66, 86, 167, 416], 211: [66, 198], 170: [66, 123, 124, 377, 437, 488], 402: [66, 76, 233, 348, 354, 397], 120: [67, 191, 377], 34: [67, 86, 112, 136, 152, 163, 182, 224, 225, 271], 291: [69, 95, 319], 355: [72, 195, 196, 355], 334: [72, 89, 100, 149], 331: [74, 185], 27: [74, 457], 133: [74, 115, 295, 344], 37: [75, 120, 413], 274: [76, 81, 159, 465, 492], 350: [77, 152, 259, 329, 347, 370], 32: [78, 79, 243, 261, 380, 389, 468], 21: [78, 205, 220, 268, 279, 302, 319], 256: [80, 81, 83, 115, 172, 175, 426], 80: [80, 170, 214, 377, 388, 487], 73: [80, 168, 183, 376], 311: [83, 245], 108: [83, 178, 496], 280: [84, 247, 411], 409: [84, 148, 169, 318, 390, 494], 135: [84, 122, 208, 220], 299: [85, 162, 456, 458], 306: [85, 95, 117, 145, 200, 280, 445], 301: [86, 142], 33: [86, 365], 174: [86, 97, 164, 209, 244, 277, 473, 490], 44: [87, 356, 417], 376: [87, 106], 84: [88, 127, 139, 216, 280, 341, 372], 171: [89, 235, 463], 68: [90, 180, 242], 413: [93, 131, 180, 356], 374: [94, 142, 145], 384: [95, 127, 145, 218, 407, 482], 400: [99, 231, 246, 349, 427, 428], 195: [100, 470], 255: [101, 102, 143, 241, 351, 366, 460, 473], 16: [102, 387], 447: [103, 131, 166, 178], 307: [104, 122, 325], 386: [104], 393: [105, 125, 355], 435: [106, 322, 330, 444], 391: [110, 118, 119, 338, 429, 453, 483], 19: [111, 475], 15: [113, 179, 313], 449: [113, 144, 242, 248, 360], 285: [114], 321: [115, 192], 415: [117, 213, 341], 328: [118, 162, 418], 185: [118, 147, 178, 211, 462], 119: [121, 295, 383, 443], 219: [122], 414: [123], 23: [123, 283], 126: [124], 270: [127, 151, 162, 193, 223, 289, 342, 461, 469], 399: [129, 217, 401], 359: [130, 274, 470], 62: [131, 162, 206, 250, 416], 204: [131, 158, 309, 345, 445], 123: [133, 206, 392], 286: [134, 166, 186, 207, 237, 276], 373: [135, 159, 228, 294, 320, 325, 364], 90: [136, 162, 178, 217, 254, 450], 238: [136, 378], 182: [137, 148, 334, 456, 467], 363: [139, 148, 189, 390], 440: [140, 337, 389, 462], 302: [142, 277], 287: [142, 288, 333, 352, 433, 437], 167: [144], 317: [144, 227, 248, 321, 357, 454], 425: [144], 448: [144, 204, 239, 243, 306, 348, 373, 448, 458, 466, 473], 267: [151, 331, 468], 183: [151, 495], 438: [152], 186: [153, 249, 297, 326, 365, 376, 451], 223: [153, 260, 285, 291, 305, 432], 78: [154], 259: [155], 60: [157, 485], 104: [158, 275, 439], 271: [159, 336], 207: [160], 354: [161, 273, 370], 132: [162, 179, 286, 393, 397, 415, 429, 490], 157: [166, 438], 419: [167, 354], 7: [168, 173, 182, 274, 356], 246: [169, 396, 492], 149: [170, 176, 226, 341, 343, 425], 260: [171, 176, 291, 495], 253: [172], 340: [173, 412], 227: [174], 1: [176, 475], 111: [179, 204, 236, 281, 393, 461], 357: [180], 57: [181], 239: [182, 380], 252: [185, 323, 465], 210: [185], 13: [186, 232, 362], 150: [188, 312], 293: [197, 305], 304: [202, 332], 97: [203], 352: [204], 243: [211, 425], 247: [212], 38: [215, 371, 410], 371: [220, 406], 258: [229, 419, 453, 460], 166: [231], 303: [232, 239, 269], 203: [234, 235, 251, 256, 342], 236: [236], 187: [239, 461], 199: [242], 106: [243, 298, 303, 328], 105: [249, 284, 359, 376], 395: [252, 295, 342], 116: [253, 394], 296: [255, 469], 420: [257], 2: [257], 194: [257, 287], 241: [258, 382, 477], 216: [266, 349, 423], 24: [270], 18: [276], 61: [278, 287, 343, 498], 230: [280, 311, 433], 155: [283, 343], 422: [293], 237: [301, 302, 413, 438], 315: [316], 5: [320, 455], 429: [322], 131: [330], 254: [331, 352], 218: [335], 154: [338], 103: [354, 360, 424], 206: [355, 383], 348: [361], 441: [368], 52: [369], 222: [374], 91: [375], 367: [375, 386], 380: [379], 79: [380, 458], 364: [382, 418], 101: [392], 310: [400], 82: [408, 499], 282: [410], 75: [413], 375: [419], 313: [432], 251: [439], 217: [443, 444], 148: [446], 63: [452], 344: [460], 102: [470], 265: [480], 139: [483]}\n",
            "Acceptance Threshold Sequence:  {0: 0.0833396834756116, 114: 0.09842769347017076, 135: 0.18958376172773275, 145: 0.086077357032155, 151: 0.10428202070276466, 307: 0.046462585929391925, 333: 0.13232549904528262, 357: 0.10795537585451877, 396: 0.05102396805238055, 57: 0.07313006997764016, 444: 0.059017789028383505, 489: 0.13198712731222817, 79: 0.06870012430868494, 126: 0.09816307881117806, 221: 0.1271335519217976, 319: 0.10957998028066412, 442: 0.10171441286839286, 492: 0.1370608401601781, 1: 0.1161762802947165, 15: 0.04743210894935525, 35: 0.1969230342783604, 43: 0.09572399888486985, 110: 0.10741808734011393, 398: 0.05388078904797455, 6: 0.1839139082497471, 80: 0.06422487487520483, 282: 0.12757029888508606, 371: 0.10727402709542243, 432: 0.06106707603472275, 179: 0.06088848085709284, 52: 0.028756622534009554, 58: 0.11194903176110119, 84: 0.10513848601129937, 86: 0.17791077410504555, 115: 0.1171483666533659, 123: 0.09946366783677095, 272: 0.10746851024769692, 301: 0.11091135493351044, 313: 0.09886267298242535, 49: 0.1117938180429722, 62: 0.10545870409992686, 195: 0.06085395944021538, 327: 0.03529457914825375, 399: 0.09691544242619125, 435: 0.10528672552759846, 493: 0.1537777392073156, 2: 0.11357438318145481, 74: 0.10266653656907075, 117: 0.11445967234280008, 127: 0.11792449110335954, 171: 0.1233381237373034, 230: 0.18601175447758142, 361: 0.12704428868799655, 91: 0.1351257926881085, 143: 0.21668005809629268, 150: 0.053148669337280366, 312: 0.1518863040557362, 383: 0.10904250523187892, 122: 0.19601712851287992, 167: 0.10688694066548168, 240: 0.1654366475274653, 3: 0.07104276494029273, 136: 0.10091323722942273, 201: 0.13098490984399044, 270: 0.09687434503873917, 292: 0.05990242658456488, 316: 0.05933039378332086, 349: 0.09313300916087507, 363: 0.09870964847976416, 400: 0.179054069460655, 98: 0.07876817369905284, 155: 0.15692841254775222, 213: 0.16980621493001358, 279: 0.10519641938143184, 482: 0.11697427962130846, 497: 0.04663876833948726, 7: 0.003202397912902638, 130: 0.1263164845953845, 163: 0.16844634279173692, 210: 0.10489857570898985, 331: 0.1299428844690299, 387: 0.12234449850028842, 475: 0.017267049782733884, 494: 0.04674898257280352, 17: 0.11363657311325101, 129: 0.13561158372563062, 304: 0.13133475541429288, 402: 0.04513602153650203, 4: 0.1313722296929008, 9: 0.1621315572423892, 108: 0.002120326281288415, 119: 0.14303883367738732, 406: 0.08216397236561909, 417: 0.1318233322653133, 82: 0.05026183255933739, 133: 0.07848642437818588, 141: 0.052623393691574094, 183: 0.08360728005707226, 284: 0.09434729955356885, 78: 0.03165655062663676, 125: 0.01899577567499941, 36: 0.05328590672947203, 187: 0.15583223191346252, 190: 0.03545426117505232, 281: 0.1216162416728801, 448: 0.11207783363504231, 113: 0.09891563914633802, 169: 0.10018416666853552, 412: 0.11733117069191386, 53: 0.04301534996567705, 116: 0.1368843032958544, 428: 0.13533812129355693, 472: 0.1404482148185594, 229: 0.06510273989987142, 245: 0.12175234672483018, 421: 0.20842196079459718, 5: 0.09759889137295222, 39: 0.12663265732427975, 157: 0.18082879085492226, 258: 0.17041968252979123, 314: 0.09353557588225388, 358: 0.17616752040678388, 89: 0.07625309784452754, 99: 0.14762592037712507, 286: 0.09342848402378125, 438: 0.14198141980250403, 478: 0.13773493519041513, 66: 0.17426586781078982, 321: 0.13427743766043115, 449: 0.07273674662585851, 112: 0.10095036823822198, 252: 0.09576087341018023, 454: 0.15381677045616213, 19: 0.1452431496515645, 41: 0.1530553479211578, 184: 0.0471982083095816, 255: 0.023683982893177663, 336: 0.15555969077907095, 379: 0.177338880987147, 38: 0.12503005978504142, 217: 0.029910663456475584, 253: 0.11693741125127977, 339: 0.055138791358269074, 405: 0.07979491411779259, 409: 0.09500335116119478, 440: 0.16005786059869376, 222: 0.06311737557390049, 348: 0.05374018370000048, 360: 0.0788859905762073, 485: 0.10942630273613638, 499: 0.027771016034434423, 174: 0.15048013997543, 298: 0.09455058734235856, 317: 0.040849553564607094, 12: 0.052195633033078365, 215: 0.09949851636175874, 259: 0.17368304712923763, 278: 0.15837857402645264, 434: 0.13598819964520972, 8: 0.17337230517035074, 299: 0.16889938656654968, 395: 0.11213412773615357, 45: 0.13439914407933656, 71: 0.13912077811702844, 205: 0.07631213401765767, 238: 0.12734262522183343, 359: 0.05580629361498288, 450: 0.08239567808694795, 479: 0.06230125196522035, 118: 0.0801995985896499, 268: 0.06246506393344962, 300: 0.13508619126849958, 373: 0.10875772939984235, 401: 0.04961821783927093, 474: 0.1644713549975953, 491: 0.09992125254875096, 48: 0.07152339223572718, 160: 0.09137532181544071, 194: 0.178203520834258, 367: 0.16493496367792385, 13: 0.12331032862464472, 75: 0.1393602552285467, 107: 0.06805043336716499, 148: 0.05663538966606407, 206: 0.10157335219232846, 231: 0.047144707412582455, 403: 0.0904218021341349, 469: 0.16906563695262594, 121: 0.06249638337822382, 227: 0.14968337256234907, 264: 0.14412490690312846, 384: 0.13345997513782454, 390: 0.07306096436190168, 488: 0.06800355853246717, 88: 0.06449504064269415, 120: 0.10616845935144024, 248: 0.10994022508250018, 352: 0.1156030220829245, 382: 0.10153331522073096, 459: 0.09707720721694527, 137: 0.04496477695845567, 147: 0.07814823576819867, 330: 0.06048841383415911, 337: 0.1720678797605956, 346: 0.07651917058424469, 350: 0.09959643918897285, 414: 0.06699606656284962, 310: 0.15717106649728446, 368: 0.1336896469859713, 446: 0.08460474053503603, 498: 0.17953804550437305, 14: 0.0108195191951697, 16: 0.18257452929658163, 25: 0.086184941082899, 233: 0.05397156541250712, 256: 0.13681488130916447, 306: 0.10163308968850815, 378: 0.07916514682818851, 96: 0.0487231413808773, 172: 0.04818957178985468, 283: 0.004439257902049992, 311: 0.05801603545709397, 318: 0.11357191111144428, 50: 0.1326702319634079, 102: 0.17491606663269826, 144: 0.05795379893135166, 176: 0.1289277910489825, 197: 0.13783053882478583, 340: 0.09908370886405746, 466: 0.021187692516508233, 55: 0.17133154838287917, 30: 0.0755841154998794, 68: 0.08091864845443165, 418: 0.1051203527468711, 457: 0.10555946509863759, 464: 0.1592275712061426, 10: 0.07289121353927407, 164: 0.029899220384124695, 134: 0.10701302921891968, 285: 0.023504523680986447, 290: 0.05378236844379182, 476: 0.025804108425202046, 21: 0.1446121140118896, 56: 0.06476506782864569, 162: 0.12755942999582187, 192: 0.04036295634290067, 247: 0.18337354406096074, 486: 0.19712222112447314, 87: 0.04871061604021448, 109: 0.07647619580150823, 430: 0.028473882097726486, 11: 0.13274355774097066, 27: 0.17051202421590017, 42: 0.20142739410586788, 209: 0.15327659413411848, 325: 0.11841381408593055, 267: 0.10853708452734277, 365: 0.10531458420444334, 47: 0.09951057475671209, 63: 0.12053910249808972, 70: 0.12253353472853445, 207: 0.18711822351924481, 353: 0.0676915661442965, 193: 0.15491056264723674, 262: 0.1247679971158256, 289: 0.08985963377196317, 34: 0.2259811805294678, 381: 0.1169985711524725, 293: 0.09563463877358, 276: 0.058993308806758626, 392: 0.10220838774131195, 65: 0.07130589489864644, 212: 0.08882923461101626, 218: 0.08544537986088828, 481: 0.054122569048819014, 175: 0.10090718786005631, 261: 0.1324909804592919, 320: 0.15437755500971098, 140: 0.14149818751597443, 178: 0.12526499040872155, 251: 0.06293621164735076, 303: 0.03927278932971589, 219: 0.03152038960513988, 471: 0.04024838751312903, 200: 0.11410807763256707, 85: 0.021790693388453547, 394: 0.13154706506907335, 445: 0.038680651034463824, 496: 0.12434109869548296, 61: 0.07660041784910239, 291: 0.18321398173849232, 309: 0.15697119553174516, 328: 0.0017977886076835509, 422: 0.033383538959225495, 463: 0.15110040873879388, 51: 0.17924500950210906, 104: 0.09219350577813146, 223: 0.022725485873862444, 266: 0.14166802631316022, 374: 0.13913371084905618, 177: 0.1309760796536984, 294: 0.09800762910876767, 462: 0.1603082149314891, 389: 0.09317519507295849, 31: 0.15028803573982394, 100: 0.16300782468563363, 334: 0.03939419461620541, 335: 0.07893535366883608, 344: 0.1877481058253251, 81: 0.10406516418625547, 156: 0.06881317555631063, 236: 0.10051732316737101, 431: 0.12445416023838714, 480: 0.056758796054045546, 203: 0.018547209546783197, 165: 0.15757075245980004, 202: 0.09695887778094225, 237: 0.143463459579907, 277: 0.09173389877936697, 18: 0.13259500448588155, 106: 0.101337468688161, 29: 0.0620615033818101, 97: 0.16627393719053496, 154: 0.151427717435404, 214: 0.14137938299593608, 20: 0.14793738999255857, 40: 0.09983267461736219, 305: 0.0931318424192274, 419: 0.03721272518751993, 426: 0.008729660616253743, 168: 0.07252353175474341, 287: 0.08469690473086228, 297: 0.14906771296237817, 94: 0.035076460618759894, 153: 0.05351388399692528, 250: 0.1613616963883156, 347: 0.07325760677950292, 372: 0.04855878191515163, 265: 0.10314970061025988, 103: 0.08082986794109762, 191: 0.0674168717067413, 246: 0.09165381324460697, 366: 0.09294926707575979, 404: 0.14370797899313384, 216: 0.09045331447712147, 477: 0.04469536993564064, 60: 0.0028613182567638618, 142: 0.05855495173858363, 235: 0.07998132680997955, 93: 0.12906096534097816, 296: 0.04305249536306165, 447: 0.1423649815424847, 22: 0.11985614339131295, 467: 0.16150398651119896, 420: 0.15610343089729167, 456: 0.1778723332901454, 315: 0.03801433158394575, 408: 0.0849975720072973, 146: 0.03154560452565712, 181: 0.0867030155974156, 186: 0.031103166481996222, 226: 0.027246354404051404, 23: 0.07574465851825311, 101: 0.05997364544425304, 391: 0.06223392558876709, 139: 0.08782458651104065, 149: 0.14237094428211988, 161: 0.1587336534297358, 199: 0.15895318227063998, 410: 0.20772649481059557, 24: 0.02495892906467931, 269: 0.14881338854951842, 32: 0.18281230747419275, 385: 0.0412430819921383, 411: 0.19449296750165504, 69: 0.03258447033728938, 465: 0.10649439566659696, 26: 0.10412956569011295, 132: 0.05019027747865704, 322: 0.0785208044759985, 369: 0.04755107374142301, 92: 0.10981240171489183, 152: 0.15378827076627885, 170: 0.04572931276586494, 208: 0.054991115734075044, 263: 0.07212456308309427, 67: 0.04460403661420812, 28: 0.12863744942510488, 158: 0.13540716248668122, 362: 0.15001306861744343, 423: 0.05988829594184032, 326: 0.017811956532526055, 441: 0.035401076848596336, 260: 0.14228374163116836, 436: 0.06727227740347791, 224: 0.13123797906694515, 254: 0.070953112514942, 73: 0.07643206166244539, 77: 0.10650051191661844, 189: 0.02154802117879881, 407: 0.11094490455491302, 332: 0.03631766144343282, 232: 0.04764658326065674, 33: 0.14145567015520122, 468: 0.1163114984724018, 111: 0.11298119295040411, 211: 0.14474337875412324, 345: 0.1054094190467983, 487: 0.0854207460103555, 54: 0.09279682811639924, 128: 0.06527389946750847, 455: 0.12358813525557867, 90: 0.044027433534891774, 196: 0.10167411045149397, 173: 0.09639397220908794, 244: 0.12535420403465453, 453: 0.15149327982877622, 324: 0.06876523164024755, 44: 0.126101965959171, 288: 0.08699828220701146, 375: 0.11712127554212229, 415: 0.12250413384862156, 271: 0.12051930669469159, 433: 0.10356791985856367, 105: 0.12552253460620386, 416: 0.058755068770918836, 249: 0.0710236730795061, 275: 0.10607911373340835, 425: 0.07513943878759181, 37: 0.006226664263016685, 166: 0.04943296750420746, 188: 0.05977401118556966, 83: 0.03735943168665551, 452: 0.14876673424912082, 351: 0.05628657220391935, 234: 0.05435452824064858, 424: 0.026108452408043825, 427: 0.08426184800894473, 59: 0.1207943984716757, 76: 0.03743769110788868, 95: 0.08705012468419364, 138: 0.09146987890256725, 302: 0.06710036847950601, 72: 0.10236392859503457, 338: 0.1464439032390626, 323: 0.14472867820699648, 225: 0.11923706638399117, 439: 0.12836898754602222, 308: 0.05899200971344951, 490: 0.11181581581506048, 393: 0.15961097827335058, 429: 0.12211031182031182, 451: 0.09003202724937114, 273: 0.14760090658410718, 386: 0.07007337422497377, 364: 0.03824222743711633, 198: 0.045261504608716134, 484: 0.11336995999884905, 46: 0.11664909849784438, 495: 0.14239237524351672, 443: 0.10384596305197698, 64: 0.17995942033653545, 228: 0.12233931925043545, 397: 0.021863928674304464, 274: 0.1374002040436405, 329: 0.09104293061722299, 483: 0.11422126594066234, 241: 0.052393131729891754, 124: 0.09284564291871492, 437: 0.08838649763460113, 388: 0.0847058160395142, 370: 0.09282412351949812, 131: 0.16643823853385561, 377: 0.07845092438704128, 354: 0.10493687728419131, 182: 0.16412849575459504, 355: 0.14290887833636362, 185: 0.07922643911499458, 295: 0.13434927476364766, 413: 0.19131390030017176, 159: 0.12188737393378953, 243: 0.10421337881301854, 380: 0.019671297987125552, 220: 0.11763664104393717, 376: 0.09079324512728239, 458: 0.10258889836277424, 280: 0.1613396277842679, 473: 0.06972468796513706, 356: 0.10990019036555565, 341: 0.21403402385995757, 180: 0.1434700158394486, 242: 0.16453631450767064, 470: 0.042721603622821624, 460: 0.06789173664040626, 342: 0.15946769626968793, 461: 0.13103728150058358, 204: 0.2074777435131835, 239: 0.05240632815398544, 343: 0.19186119261633944, 257: 0.10888120072147864}\n"
          ]
        }
      ],
      "source": [
        "n = 500  # Number of nodes\n",
        "\n",
        "# Information Layer\n",
        "gamma_i = 2.5  # Power-law exponent\n",
        "kmin_i = 3  # Minimum degree\n",
        "num_hyper_edges_i = 450  # Desired number of hyper edges\n",
        "ldeg_i, hyperedge_dict_i = build_hypergraph(n, gamma_i, kmin_i, num_hyper_edges_i)\n",
        "inw = hnx.Hypergraph(hyperedge_dict_i)\n",
        "ltre = assign_thresholds(inw, 0.10, 0.05)\n",
        "print(\"Acceptance Threshold Sequence: \", ltre)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dyx9fct99ER",
        "outputId": "5ea0f71f-78d4-4326-fff7-896e339056e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Behavior Degree Sequence:  [3, 9, 6, 3, 3, 6, 3, 3, 3, 3, 5, 5, 3, 3, 6, 6, 5, 3, 4, 3, 3, 3, 3, 3, 8, 3, 3, 5, 3, 4, 6, 3, 3, 4, 3, 5, 5, 7, 3, 4, 3, 3, 3, 3, 4, 4, 5, 4, 4, 3, 3, 3, 3, 6, 3, 3, 3, 9, 3, 8, 4, 3, 3, 11, 3, 3, 3, 4, 6, 3, 4, 5, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 5, 3, 4, 3, 3, 3, 3, 3, 6, 7, 3, 3, 3, 3, 4, 3, 3, 5, 4, 3, 3, 3, 4, 4, 5, 3, 3, 3, 3, 3, 3, 4, 3, 6, 5, 6, 3, 13, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
          ]
        }
      ],
      "source": [
        "# Cognition Layer\n",
        "gamma_c = 3.0  # Power-law exponent\n",
        "kmin_c = 3  # Minimum degree\n",
        "ldeg_c = generate_degree_sequence(n, gamma_c, kmin_c)\n",
        "print(\"Behavior Degree Sequence: \", ldeg_c)\n",
        "cnw = nx.configuration_model(ldeg_c)\n",
        "frac_prot = 0.05\n",
        "lprot = assign_protection(cnw, frac_prot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKafDk93992O",
        "outputId": "e5259bf4-cca4-49e8-a779-64c4b4033339"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Degree Sequence:  [3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 6, 5, 3, 3, 3, 3, 3, 4, 3, 4, 3, 5, 3, 3, 5, 3, 4, 6, 3, 7, 4, 4, 3, 3, 4, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 4, 3, 3, 4, 5, 3, 3, 3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
            "['<k>: ', 4.5, '<k^2>: ', 27.0, '(<k^2>-<k>)/<k>: ', 5.0]\n"
          ]
        }
      ],
      "source": [
        "# Epidemic Layer\n",
        "gamma_e = 4.0 #gamma_e = 4.75   #gamma_e = 4.0\n",
        "kmin_e = 3\n",
        "ldeg_e = generate_degree_sequence(n, gamma_e, kmin_e)\n",
        "print(\"Degree Sequence: \", ldeg_e)\n",
        "enw = nx.configuration_model(ldeg_e)\n",
        "k = ((gamma_e-1)/(gamma_e-2))*(kmin_e) #<k>\n",
        "k2 =((gamma_e-1)/(gamma_e-3))*((kmin_e)**2) #<k^2>\n",
        "division_factor = (k2-k)/k # division factor to compute beta_max(<k^2>-<k>)/<k>\n",
        "print([\"<k>: \", k, \"<k^2>: \", k2,\"(<k^2>-<k>)/<k>: \",  division_factor])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGOHKVGoPuRu",
        "outputId": "0018b100-4568-44b9-b1b9-c3e810f409b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZmxKUmF5Cfd"
      },
      "outputs": [],
      "source": [
        "def ICE_model_record_layer_education(inw, ldeg_i, ltre, cnw, ldeg_c, lprot, enw, ldeg_e, lam, alp, omega, sigma, phi, zeta_1, zeta_2, zeta_3, zeta_4, beta_PP, beta_NP, beta_PN, beta_NN, mu, n_sample):\n",
        "\n",
        "  t_max = 1000      # Set maximum time\n",
        "  kmax_i = max (ldeg_i)     # Get maximum hyperedge degree in information layer\n",
        "  kmax_c = max (ldeg_c)     # Get maximum hyperedge degree in cognition layer\n",
        "  kmax_e = max (ldeg_e)     # Get maximum degree in epidemic layer\n",
        "  N = inw.order()  # Get the network size\n",
        "\n",
        "  rho_A = []   # Keep track of fraction of stifler in information layer\n",
        "  rho_P = []   # Keep track of fraction of protected in cognition layer\n",
        "  rho_R = []   # Keep track of fraction of recovered in epidemic layer\n",
        "\n",
        "  for i_samp in range(1, n_sample + 1):\n",
        "      t = 0                 # Initialize time, number of corrected, number of recovered\n",
        "      N_corrected = 0\n",
        "      N_recovered = 0\n",
        "      N_stifler = 0\n",
        "\n",
        "      info_states = {j: \"U\" for j in inw.nodes()}   # Initialize information and disease states\n",
        "      disease_states = {k: \"S\" for k in enw.nodes()}\n",
        "\n",
        "      lprot = assign_protection(cnw, frac_prot)\n",
        "      protected = list(filter(lambda node: lprot[node] == \"P\", lprot))\n",
        "      N_protected = len(protected)\n",
        "      not_protected = list(filter(lambda node: lprot[node] == \"N\", lprot))\n",
        "\n",
        "      gossip = []     # Create lists to store gossip and corrected individuals in information layer\n",
        "      corrected = []\n",
        "      stifler = []\n",
        "\n",
        "      N_gossip = 0\n",
        "      N_e_i = 0\n",
        "\n",
        "      infected = []     # Create lists to store infected and recovered individuals in epidemic layer\n",
        "      recovered = []\n",
        "\n",
        "      time_record= [0]\n",
        "      recovered_count = [0]\n",
        "\n",
        "      N_infected = 0\n",
        "      N_e_e = 0\n",
        "      for _ in range(10):\n",
        "          ill_node_0 = np.random.choice([node for node, state in disease_states.items() if state == \"S\" and node in enw.nodes()])\n",
        "          disease_states[ill_node_0] = \"I\"\n",
        "          infected.append(ill_node_0)\n",
        "          N_infected += 1\n",
        "          N_e_e += enw.degree(ill_node_0)\n",
        "\n",
        "      beta_max = max(beta_PP,beta_NP,beta_PN,beta_NN) # Chose the largest infection rate (I known that it is beta_NN, but keep it general)\n",
        "\n",
        "      while t < 150 and N_infected > 0:   # We stop when there is no infection\n",
        "        total_rate = lam * N_e_i + 2 * alp * N_e_i + beta_max * N_e_e + mu * N_infected + zeta_1 * N_protected + zeta_2 * (N-N_protected) + zeta_3 * N_protected + zeta_4 * (N-N_protected) + omega * N_stifler + sigma * N_e_i + sigma * N_gossip + phi * N_corrected\n",
        "        tau = -np.log(np.random.uniform(1e-6, 1)) / total_rate\n",
        "        t += tau\n",
        "\n",
        "        if t >= t_max:\n",
        "                break\n",
        "\n",
        "      # Determine which event occurs\n",
        "        event = np.random.uniform()\n",
        "        p1 = (lam * N_e_i) / total_rate     # rumor spreading\n",
        "        p2 = (lam * N_e_i + alp * N_e_i) / total_rate  # rumor stifling (by meeting stifling neighbor threshold)\n",
        "        p3 = (lam * N_e_i + 2 * alp * N_e_i) / total_rate  # rumor stifling (by meeting gossip neighbor threshold)\n",
        "\n",
        "        p4 = (lam * N_e_i + 2 * alp * N_e_i + beta_max * N_e_e) / total_rate  # disease propagation\n",
        "        p5 = (lam * N_e_i + 2 * alp * N_e_i + beta_max * N_e_e + mu * N_infected) / total_rate  # disease recovery\n",
        "\n",
        "        p6 = (lam * N_e_i + 2 * alp * N_e_i + beta_max * N_e_e + mu * N_infected + zeta_1 * N_protected) / total_rate # change to not adopting protection by information\n",
        "        p7 = (lam * N_e_i + 2 * alp * N_e_i + beta_max * N_e_e + mu * N_infected + zeta_1 * N_protected + zeta_2 * (N-N_protected) ) / total_rate # change to adopting protection by information\n",
        "        p8 = (lam * N_e_i + 2 * alp * N_e_i + beta_max * N_e_e + mu * N_infected + zeta_1 * N_protected + zeta_2 * (N-N_protected)  + zeta_3 * N_protected) / total_rate # change to not adopting protection by neighborhood behavior\n",
        "        p9 = (lam * N_e_i + 2 * alp * N_e_i + beta_max * N_e_e + mu * N_infected + zeta_1 * N_protected + zeta_2 * (N-N_protected) + zeta_3 * N_protected + zeta_4 * (N-N_protected))/total_rate # change to adopting protection by neighborhood behavior\n",
        "        p10 = (lam * N_e_i + 2 * alp * N_e_i + beta_max * N_e_e + mu * N_infected + zeta_1 * N_protected + zeta_2 * (N-N_protected) + zeta_3 * N_protected + zeta_4 * (N-N_protected) + omega * N_stifler)/total_rate # rumor interest renewal\n",
        "        p11 = (lam * N_e_i + 2 * alp * N_e_i + beta_max * N_e_e + mu * N_infected + zeta_1 * N_protected + zeta_2 * (N-N_protected) + zeta_3 * N_protected + zeta_4 * (N-N_protected) + omega * N_stifler + sigma * N_e_i)/total_rate # gossip correction by education\n",
        "        p12 = (lam * N_e_i + 2 * alp * N_e_i + beta_max * N_e_e + mu * N_infected + zeta_1 * N_protected + zeta_2 * (N-N_protected) + zeta_3 * N_protected + zeta_4 * (N-N_protected) + omega * N_stifler + sigma * N_e_i + sigma * N_gossip)/total_rate # gossip correction from outside\n",
        "        # >p12 relapse\n",
        "\n",
        "        # Determine if accept selected individual based on degree distribution\n",
        "        q_deg_i = np.random.uniform()\n",
        "        q_deg_c = np.random.uniform()\n",
        "        q_deg_e = np.random.uniform()\n",
        "\n",
        "        # Case 1: Rumor spreading\n",
        "        if event < p1:\n",
        "                response='F'\n",
        "                while len(gossip)>0 and response =='F':\n",
        "                  gossip_node = np.random.choice(gossip) #chose an infected node proportional to the degree\n",
        "                  draw_rn = np.random.uniform()\n",
        "                  if draw_rn < inw.degree(gossip_node)/kmax_i:\n",
        "                     response='T'\n",
        "\n",
        "                edges_containing_gossip = [edge for edge in inw.edges() if gossip_node in inw[edge]]\n",
        "                if edges_containing_gossip:\n",
        "                        rumor_hyper_edge = np.random.choice(edges_containing_gossip)\n",
        "                        neighbors = inw[rumor_hyper_edge]\n",
        "                        for neighbor in neighbors:\n",
        "                            if info_states[neighbor] == \"U\":\n",
        "                                count_gossip_neighbors = sum(1 for node in inw.neighbors(neighbor) if info_states[node] == \"G\")\n",
        "                                if count_gossip_neighbors / len(inw.neighbors(neighbor)) >= ltre[neighbor]:\n",
        "                                    info_states[neighbor] = \"G\"  # uninformed neighbor becomes gossip spreader\n",
        "                                    gossip.append(neighbor)\n",
        "                                    N_gossip += 1\n",
        "                                    N_e_i += inw.degree(neighbor)\n",
        "\n",
        "        # Case 2: Rumor stifling (by meeting stifling neighbor threshold)\n",
        "        elif event < p2:\n",
        "                    response='F'\n",
        "                    while len(gossip)>0 and response =='F':\n",
        "                      stifler_node = np.random.choice(gossip) #chose an infected node proportional to the degree\n",
        "                      draw_rn = np.random.uniform()\n",
        "                      if draw_rn < inw.degree(stifler_node)/kmax_i:\n",
        "                         response='T'\n",
        "\n",
        "                    stifler_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                    neighbors = inw[stifler_hyper_edge]\n",
        "                    count_stifler_neighbors = sum(1 for node in inw.neighbors(stifler_node) if info_states[node] == \"A\")\n",
        "                    if count_stifler_neighbors > 0:\n",
        "                            info_states[stifler_node] = \"A\"\n",
        "                            N_gossip -= 1\n",
        "                            gossip.remove(stifler_node)\n",
        "                            stifler.append(stifler_node)\n",
        "                            N_stifler += 1\n",
        "                            N_e_i -= inw.degree(stifler_node)\n",
        "\n",
        "        # Case 3: Rumor stifling (by meeting gossip neighbor threshold)\n",
        "        elif event < p3:\n",
        "                    response='F'\n",
        "                    while len(gossip)>0 and response =='F':\n",
        "                      stifler_node = np.random.choice(gossip) #chose an infected node proportional to the degree\n",
        "                      draw_rn = np.random.uniform()\n",
        "                      if draw_rn < inw.degree(stifler_node)/kmax_i:\n",
        "                         response='T'\n",
        "\n",
        "                    stifler_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                    neighbors = inw[stifler_hyper_edge]\n",
        "                    count_gossip_neighbors = sum(1 for node in inw.neighbors(stifler_node) if info_states[node] == \"G\")\n",
        "                    if count_gossip_neighbors > 0:\n",
        "                            info_states[stifler_node] = \"A\"\n",
        "                            N_gossip -= 1\n",
        "                            gossip.remove(stifler_node)\n",
        "                            stifler.append(stifler_node)\n",
        "                            N_stifler += 1\n",
        "                            N_e_i -= inw.degree(stifler_node)\n",
        "\n",
        "        # Case 4: Disease propagation\n",
        "        elif event < p4:\n",
        "            # code based on the new pseudo code\n",
        "            response='F'\n",
        "            while len(infected)>0 and response =='F':  #draw node until degree distribution is reached and while the infected list is not empty\n",
        "              infected_node = np.random.choice(infected) #choose an infected node proportional to the degree\n",
        "              draw_rn = np.random.uniform()\n",
        "              if draw_rn < enw.degree(infected_node)/kmax_e: # kmax_e is the global max degree\n",
        "                 response='T'\n",
        "\n",
        "            neighbors = list(enw.neighbors(infected_node)) #get the list of neighbors of the infected node\n",
        "            target_node = np.random.choice(neighbors) #choose a neighbor at random\n",
        "            # beta_NN > beta_PN > beta_NP > beta_PP\n",
        "            if disease_states[target_node] == \"S\":\n",
        "                if lprot[target_node] == \"P\" and lprot[infected_node] == \"P\":\n",
        "                   beta_correct = beta_PP\n",
        "                elif lprot[target_node] == \"N\" and lprot[infected_node] == \"P\":\n",
        "                   beta_correct = beta_NP\n",
        "                elif lprot[target_node] == \"P\" and lprot[infected_node] == \"N\":\n",
        "                   beta_correct = beta_PN\n",
        "                else:\n",
        "                   beta_correct = beta_NN\n",
        "\n",
        "                draw_rn = np.random.uniform()\n",
        "                if draw_rn < beta_correct/beta_max:\n",
        "                   disease_states[target_node] = \"I\"\n",
        "                   infected.append(target_node)\n",
        "                   N_infected += 1\n",
        "                   N_e_e += enw.degree(target_node)\n",
        "\n",
        "                   ## Start gossip after epidemic have started\n",
        "                   if N_gossip == 0:\n",
        "                      uninformed = [node for node, state in info_states.items() if state == \"U\" and node in inw.nodes()]\n",
        "                      if len(uninformed) > 0:\n",
        "                        rumor_node_0 = np.random.choice(uninformed)\n",
        "                        info_states[rumor_node_0] = \"G\"\n",
        "                        gossip.append(rumor_node_0)\n",
        "                        N_gossip += 1\n",
        "                        N_e_i += inw.degree(rumor_node_0)\n",
        "\n",
        "        # Case 5: Disease recovery\n",
        "        elif event < p5:\n",
        "                  recovered_node = np.random.choice(infected)\n",
        "                  disease_states[recovered_node] = \"R\"\n",
        "                  infected.remove(recovered_node)\n",
        "                  recovered.append(recovered_node)\n",
        "                  N_infected -= 1\n",
        "                  N_recovered += 1\n",
        "                  N_e_e -= enw.degree(recovered_node)\n",
        "                  time_record.append(t)\n",
        "                  recovered_count.append(N_recovered)\n",
        "\n",
        "        # Case 6: # Change to not adopting protection based on information layer\n",
        "        # n_G is the total spreader neighbors on the information layer,\n",
        "        # while k_info is the total neighbor count on the information layer\n",
        "        elif event < p6:\n",
        "            if len(protected) > 0:\n",
        "              node_to_not_protect = np.random.choice(protected)\n",
        "              n_G = sum(1 for node in filter(lambda x: info_states[x] == \"G\", inw.neighbors(node_to_not_protect)))\n",
        "              k_info = len(list(inw.neighbors(node_to_not_protect)))\n",
        "              frac_inf = N_infected/N\n",
        "              b = 3\n",
        "              if np.random.uniform() < (n_G / k_info) * (1-np.tanh(b*(frac_inf))):\n",
        "                    lprot[node_to_not_protect] = \"N\"\n",
        "                    protected.remove(node_to_not_protect)\n",
        "                    not_protected.append(node_to_not_protect)\n",
        "                    N_protected -= 1\n",
        "\n",
        "        # Case 7: Change to adopting protection based on information layer\n",
        "        elif event < p7:\n",
        "            if len(not_protected) > 0:\n",
        "                node_to_protect = np.random.choice(not_protected)\n",
        "                n_G = sum(1 for node in filter(lambda x: info_states[x] == \"G\", inw.neighbors(node_to_protect)))\n",
        "                k_info = len(list(inw.neighbors(node_to_protect)))\n",
        "                frac_inf = N_infected/N\n",
        "                b = 3\n",
        "                if np.random.uniform() < (1 - n_G / k_info) * np.tanh(b*(frac_inf)):\n",
        "                        lprot[node_to_protect] = \"P\"\n",
        "                        not_protected.remove(node_to_protect)\n",
        "                        protected.append(node_to_protect)\n",
        "                        N_protected += 1\n",
        "\n",
        "        # Case 8: # Change to not adopting protection based on neighborhood behavior in cognition layer\n",
        "        # n_P is the total protected neighbors on the cognition layer,\n",
        "        # while k_cog is the total neighbor count on the cognition layer\n",
        "        elif event < p8:\n",
        "            if len(protected) > 0:\n",
        "                node_to_not_protect = np.random.choice(protected)\n",
        "                n_P = sum(1 for node in filter(lambda x: lprot[x] == \"P\", cnw.neighbors(node_to_not_protect)))\n",
        "                k_cog = len(list(cnw.neighbors(node_to_not_protect)))\n",
        "                if np.random.uniform() < 1 - n_P / k_cog:\n",
        "                        lprot[node_to_not_protect] = \"N\"\n",
        "                        protected.remove(node_to_not_protect)\n",
        "                        not_protected.append(node_to_not_protect)\n",
        "                        N_protected -= 1\n",
        "\n",
        "        # Case 9: # Change to adopting protection based on neighborhood behavior in cognition layer\n",
        "        elif event < p9:\n",
        "            if len(not_protected) > 0:\n",
        "                node_to_protect = np.random.choice(not_protected)\n",
        "                n_P = sum(1 for node in filter(lambda x: lprot[x] == \"P\", cnw.neighbors(node_to_protect)))\n",
        "                k_cog = len(list(cnw.neighbors(node_to_protect)))\n",
        "                if np.random.uniform() < n_P / k_cog:\n",
        "                        lprot[node_to_protect] = \"P\"\n",
        "                        not_protected.remove(node_to_protect)\n",
        "                        protected.append(node_to_protect)\n",
        "                        N_protected += 1\n",
        "\n",
        "        # Case 10: Rumor interest renewal\n",
        "        elif event < p10:\n",
        "            if len(stifler) > 0:\n",
        "                  stifler_node = np.random.choice(stifler)\n",
        "                  info_states[stifler_node] = \"U\"\n",
        "                  stifler.remove(stifler_node)\n",
        "                  N_stifler -= 1\n",
        "\n",
        "        # Case 11: Correction of rumor by education G+C->C+C\n",
        "        elif event < p11:\n",
        "                    response='F'\n",
        "                    while len(gossip)>0 and response =='F':\n",
        "                      target_node = np.random.choice(gossip) #chose an infected node proportional to the degree\n",
        "                      draw_rn = np.random.uniform()\n",
        "                      if draw_rn < inw.degree(target_node)/kmax_i:\n",
        "                         response='T'\n",
        "\n",
        "                    target_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                    neighbors = inw[target_hyper_edge]\n",
        "                    count_corrected_neighbors = sum(1 for node in inw.neighbors(target_node) if info_states[node] == \"C\")\n",
        "                    if count_corrected_neighbors > 0:\n",
        "                            info_states[target_node] = \"C\"\n",
        "                            N_gossip -= 1\n",
        "                            gossip.remove(target_node)\n",
        "                            corrected.append(target_node)\n",
        "                            N_corrected += 1\n",
        "                            N_e_i -= inw.degree(target_node)\n",
        "\n",
        "        # Case 12: Correction of rumor from outside G->C\n",
        "        elif event < p12:\n",
        "            if len(gossip)>0:\n",
        "                correction_node = np.random.choice(gossip) #chose an infected node proportional to the degree\n",
        "                info_states[correction_node] = \"C\"\n",
        "                N_gossip -= 1\n",
        "                gossip.remove(correction_node)\n",
        "                corrected.append(correction_node)\n",
        "                N_corrected += 1\n",
        "                N_e_i -= inw.degree(correction_node)\n",
        "\n",
        "        # Case 13: Corrected become stifler\n",
        "        else:\n",
        "          if len(corrected)>0:\n",
        "                new_exposure_node = np.random.choice(corrected)\n",
        "                info_states[new_exposure_node] = \"A\"\n",
        "                N_corrected -= 1\n",
        "                corrected.remove(new_exposure_node)\n",
        "                N_stifler += 1\n",
        "                stifler.append(new_exposure_node)\n",
        "\n",
        "  return time_record, recovered_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGXdhOpI9uxj"
      },
      "outputs": [],
      "source": [
        "# No Control single run\n",
        "lam = 1/3\n",
        "alp = 1/3\n",
        "#omega = 1.4\n",
        "#sigma = 1/10\n",
        "phi = 1/5\n",
        "zeta_1 = 0.2 #go to not protect by information\n",
        "zeta_2 = 0.2 #go to protect by information\n",
        "zeta_3 = 0 #go to not protect by neighborhood behavior\n",
        "zeta_4 = 0 #go to protect by neighborhood behavior\n",
        "mu = 0.2\n",
        "R0 = 4.0 #(assume a COVID19-like disease for the reproduction number) #2.0 # reproduction number\n",
        "beta_NN = R0 * mu / division_factor\n",
        "beta_PN = beta_NN * 0.2\n",
        "beta_NP = beta_NN * 0.1\n",
        "beta_PP = beta_NN * 0.0\n",
        "n_sample = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fOKb6IxxFj7d",
        "outputId": "76868d11-6223-47f4-fcd2-4e07eff2054c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Omega: 0.0, Sigma: 0.0, Attack Rate: 0.10321999999999999\n",
            "Omega: 0.0, Sigma: 0.025, Attack Rate: 0.10304\n",
            "Omega: 0.0, Sigma: 0.05, Attack Rate: 0.09914\n",
            "Omega: 0.0, Sigma: 0.075, Attack Rate: 0.1026\n",
            "Omega: 0.0, Sigma: 0.1, Attack Rate: 0.10248\n",
            "Omega: 0.0, Sigma: 0.125, Attack Rate: 0.1016\n",
            "Omega: 0.0, Sigma: 0.15, Attack Rate: 0.10074\n",
            "Omega: 0.0, Sigma: 0.175, Attack Rate: 0.10844\n",
            "Omega: 0.0, Sigma: 0.2, Attack Rate: 0.09722\n",
            "Omega: 0.0, Sigma: 0.225, Attack Rate: 0.1016\n",
            "Omega: 0.0, Sigma: 0.25, Attack Rate: 0.101\n",
            "Omega: 0.0, Sigma: 0.275, Attack Rate: 0.10256\n",
            "Omega: 0.0, Sigma: 0.3, Attack Rate: 0.10493999999999999\n",
            "Omega: 0.0, Sigma: 0.325, Attack Rate: 0.09876\n",
            "Omega: 0.0, Sigma: 0.35, Attack Rate: 0.10490000000000001\n",
            "Omega: 0.0, Sigma: 0.375, Attack Rate: 0.10306\n",
            "Omega: 0.0, Sigma: 0.4, Attack Rate: 0.09758\n",
            "Omega: 0.0, Sigma: 0.425, Attack Rate: 0.10356\n",
            "Omega: 0.0, Sigma: 0.45, Attack Rate: 0.10044\n",
            "Omega: 0.0, Sigma: 0.475, Attack Rate: 0.10158\n",
            "Omega: 0.0, Sigma: 0.5, Attack Rate: 0.0999\n",
            "Omega: 0.1, Sigma: 0.0, Attack Rate: 0.09838\n",
            "Omega: 0.1, Sigma: 0.025, Attack Rate: 0.10004\n",
            "Omega: 0.1, Sigma: 0.05, Attack Rate: 0.10446\n",
            "Omega: 0.1, Sigma: 0.075, Attack Rate: 0.10598\n",
            "Omega: 0.1, Sigma: 0.1, Attack Rate: 0.10588\n",
            "Omega: 0.1, Sigma: 0.125, Attack Rate: 0.09759999999999999\n",
            "Omega: 0.1, Sigma: 0.15, Attack Rate: 0.09866\n",
            "Omega: 0.1, Sigma: 0.175, Attack Rate: 0.0995\n",
            "Omega: 0.1, Sigma: 0.2, Attack Rate: 0.09964\n",
            "Omega: 0.1, Sigma: 0.225, Attack Rate: 0.10482\n",
            "Omega: 0.1, Sigma: 0.25, Attack Rate: 0.10474\n",
            "Omega: 0.1, Sigma: 0.275, Attack Rate: 0.09956\n",
            "Omega: 0.1, Sigma: 0.3, Attack Rate: 0.09598000000000001\n",
            "Omega: 0.1, Sigma: 0.325, Attack Rate: 0.10308\n",
            "Omega: 0.1, Sigma: 0.35, Attack Rate: 0.10502\n",
            "Omega: 0.1, Sigma: 0.375, Attack Rate: 0.09758\n",
            "Omega: 0.1, Sigma: 0.4, Attack Rate: 0.10282\n",
            "Omega: 0.1, Sigma: 0.425, Attack Rate: 0.1013\n",
            "Omega: 0.1, Sigma: 0.45, Attack Rate: 0.10462\n",
            "Omega: 0.1, Sigma: 0.475, Attack Rate: 0.10218\n",
            "Omega: 0.1, Sigma: 0.5, Attack Rate: 0.09387999999999999\n",
            "Omega: 0.2, Sigma: 0.0, Attack Rate: 0.09764\n",
            "Omega: 0.2, Sigma: 0.025, Attack Rate: 0.10572\n",
            "Omega: 0.2, Sigma: 0.05, Attack Rate: 0.10156\n",
            "Omega: 0.2, Sigma: 0.075, Attack Rate: 0.0983\n",
            "Omega: 0.2, Sigma: 0.1, Attack Rate: 0.09984\n",
            "Omega: 0.2, Sigma: 0.125, Attack Rate: 0.10112\n",
            "Omega: 0.2, Sigma: 0.15, Attack Rate: 0.10394\n",
            "Omega: 0.2, Sigma: 0.175, Attack Rate: 0.10529999999999999\n",
            "Omega: 0.2, Sigma: 0.2, Attack Rate: 0.1025\n",
            "Omega: 0.2, Sigma: 0.225, Attack Rate: 0.0984\n",
            "Omega: 0.2, Sigma: 0.25, Attack Rate: 0.10174\n",
            "Omega: 0.2, Sigma: 0.275, Attack Rate: 0.09609999999999999\n",
            "Omega: 0.2, Sigma: 0.3, Attack Rate: 0.10443999999999999\n",
            "Omega: 0.2, Sigma: 0.325, Attack Rate: 0.09778\n",
            "Omega: 0.2, Sigma: 0.35, Attack Rate: 0.1082\n",
            "Omega: 0.2, Sigma: 0.375, Attack Rate: 0.10184\n",
            "Omega: 0.2, Sigma: 0.4, Attack Rate: 0.09922\n",
            "Omega: 0.2, Sigma: 0.425, Attack Rate: 0.10088\n",
            "Omega: 0.2, Sigma: 0.45, Attack Rate: 0.09808\n",
            "Omega: 0.2, Sigma: 0.475, Attack Rate: 0.09908\n",
            "Omega: 0.2, Sigma: 0.5, Attack Rate: 0.10604000000000001\n",
            "Omega: 0.3, Sigma: 0.0, Attack Rate: 0.10368000000000001\n",
            "Omega: 0.3, Sigma: 0.025, Attack Rate: 0.10493999999999999\n",
            "Omega: 0.3, Sigma: 0.05, Attack Rate: 0.10146\n",
            "Omega: 0.3, Sigma: 0.075, Attack Rate: 0.10593999999999999\n",
            "Omega: 0.3, Sigma: 0.1, Attack Rate: 0.10296\n",
            "Omega: 0.3, Sigma: 0.125, Attack Rate: 0.10859999999999999\n",
            "Omega: 0.3, Sigma: 0.15, Attack Rate: 0.10684\n",
            "Omega: 0.3, Sigma: 0.175, Attack Rate: 0.10542\n",
            "Omega: 0.3, Sigma: 0.2, Attack Rate: 0.1002\n",
            "Omega: 0.3, Sigma: 0.225, Attack Rate: 0.09764\n",
            "Omega: 0.3, Sigma: 0.25, Attack Rate: 0.1026\n",
            "Omega: 0.3, Sigma: 0.275, Attack Rate: 0.10056\n",
            "Omega: 0.3, Sigma: 0.3, Attack Rate: 0.10808\n",
            "Omega: 0.3, Sigma: 0.325, Attack Rate: 0.10701999999999999\n",
            "Omega: 0.3, Sigma: 0.35, Attack Rate: 0.10076\n",
            "Omega: 0.3, Sigma: 0.375, Attack Rate: 0.10479999999999999\n",
            "Omega: 0.3, Sigma: 0.4, Attack Rate: 0.09804\n",
            "Omega: 0.3, Sigma: 0.425, Attack Rate: 0.09736\n",
            "Omega: 0.3, Sigma: 0.45, Attack Rate: 0.0997\n",
            "Omega: 0.3, Sigma: 0.475, Attack Rate: 0.09536\n",
            "Omega: 0.3, Sigma: 0.5, Attack Rate: 0.10134\n",
            "Omega: 0.4, Sigma: 0.0, Attack Rate: 0.10344\n",
            "Omega: 0.4, Sigma: 0.025, Attack Rate: 0.11137999999999999\n",
            "Omega: 0.4, Sigma: 0.05, Attack Rate: 0.10058\n",
            "Omega: 0.4, Sigma: 0.075, Attack Rate: 0.10614\n",
            "Omega: 0.4, Sigma: 0.1, Attack Rate: 0.09976\n",
            "Omega: 0.4, Sigma: 0.125, Attack Rate: 0.10665999999999999\n",
            "Omega: 0.4, Sigma: 0.15, Attack Rate: 0.10098\n",
            "Omega: 0.4, Sigma: 0.175, Attack Rate: 0.10548\n",
            "Omega: 0.4, Sigma: 0.2, Attack Rate: 0.10044\n",
            "Omega: 0.4, Sigma: 0.225, Attack Rate: 0.09984\n",
            "Omega: 0.4, Sigma: 0.25, Attack Rate: 0.10018\n",
            "Omega: 0.4, Sigma: 0.275, Attack Rate: 0.10072\n",
            "Omega: 0.4, Sigma: 0.3, Attack Rate: 0.09728\n",
            "Omega: 0.4, Sigma: 0.325, Attack Rate: 0.0999\n",
            "Omega: 0.4, Sigma: 0.35, Attack Rate: 0.1032\n",
            "Omega: 0.4, Sigma: 0.375, Attack Rate: 0.09759999999999999\n",
            "Omega: 0.4, Sigma: 0.4, Attack Rate: 0.1002\n",
            "Omega: 0.4, Sigma: 0.425, Attack Rate: 0.1004\n",
            "Omega: 0.4, Sigma: 0.45, Attack Rate: 0.10426\n",
            "Omega: 0.4, Sigma: 0.475, Attack Rate: 0.10076\n",
            "Omega: 0.4, Sigma: 0.5, Attack Rate: 0.10540000000000001\n",
            "Omega: 0.5, Sigma: 0.0, Attack Rate: 0.10146\n",
            "Omega: 0.5, Sigma: 0.025, Attack Rate: 0.10466\n",
            "Omega: 0.5, Sigma: 0.05, Attack Rate: 0.10642\n",
            "Omega: 0.5, Sigma: 0.075, Attack Rate: 0.10694\n",
            "Omega: 0.5, Sigma: 0.1, Attack Rate: 0.1018\n",
            "Omega: 0.5, Sigma: 0.125, Attack Rate: 0.10352\n",
            "Omega: 0.5, Sigma: 0.15, Attack Rate: 0.1041\n",
            "Omega: 0.5, Sigma: 0.175, Attack Rate: 0.0998\n",
            "Omega: 0.5, Sigma: 0.2, Attack Rate: 0.1045\n",
            "Omega: 0.5, Sigma: 0.225, Attack Rate: 0.10552\n",
            "Omega: 0.5, Sigma: 0.25, Attack Rate: 0.10636\n",
            "Omega: 0.5, Sigma: 0.275, Attack Rate: 0.10052\n",
            "Omega: 0.5, Sigma: 0.3, Attack Rate: 0.09986\n",
            "Omega: 0.5, Sigma: 0.325, Attack Rate: 0.09473999999999999\n",
            "Omega: 0.5, Sigma: 0.35, Attack Rate: 0.09952\n",
            "Omega: 0.5, Sigma: 0.375, Attack Rate: 0.09344\n",
            "Omega: 0.5, Sigma: 0.4, Attack Rate: 0.10342\n",
            "Omega: 0.5, Sigma: 0.425, Attack Rate: 0.10402\n",
            "Omega: 0.5, Sigma: 0.45, Attack Rate: 0.09595999999999999\n",
            "Omega: 0.5, Sigma: 0.475, Attack Rate: 0.10366\n",
            "Omega: 0.5, Sigma: 0.5, Attack Rate: 0.10454000000000001\n",
            "Omega: 0.6, Sigma: 0.0, Attack Rate: 0.11109999999999999\n",
            "Omega: 0.6, Sigma: 0.025, Attack Rate: 0.10212\n",
            "Omega: 0.6, Sigma: 0.05, Attack Rate: 0.10978\n",
            "Omega: 0.6, Sigma: 0.075, Attack Rate: 0.10446\n",
            "Omega: 0.6, Sigma: 0.1, Attack Rate: 0.10212\n",
            "Omega: 0.6, Sigma: 0.125, Attack Rate: 0.10234\n",
            "Omega: 0.6, Sigma: 0.15, Attack Rate: 0.10736\n",
            "Omega: 0.6, Sigma: 0.175, Attack Rate: 0.10102\n",
            "Omega: 0.6, Sigma: 0.2, Attack Rate: 0.10002\n",
            "Omega: 0.6, Sigma: 0.225, Attack Rate: 0.10382\n",
            "Omega: 0.6, Sigma: 0.25, Attack Rate: 0.0974\n",
            "Omega: 0.6, Sigma: 0.275, Attack Rate: 0.10124\n",
            "Omega: 0.6, Sigma: 0.3, Attack Rate: 0.10126\n",
            "Omega: 0.6, Sigma: 0.325, Attack Rate: 0.10536\n",
            "Omega: 0.6, Sigma: 0.35, Attack Rate: 0.09742\n",
            "Omega: 0.6, Sigma: 0.375, Attack Rate: 0.095\n",
            "Omega: 0.6, Sigma: 0.4, Attack Rate: 0.10194\n",
            "Omega: 0.6, Sigma: 0.425, Attack Rate: 0.10154\n",
            "Omega: 0.6, Sigma: 0.45, Attack Rate: 0.10518000000000001\n",
            "Omega: 0.6, Sigma: 0.475, Attack Rate: 0.09864\n",
            "Omega: 0.6, Sigma: 0.5, Attack Rate: 0.10342\n",
            "Omega: 0.7, Sigma: 0.0, Attack Rate: 0.10895999999999999\n",
            "Omega: 0.7, Sigma: 0.025, Attack Rate: 0.11234000000000001\n",
            "Omega: 0.7, Sigma: 0.05, Attack Rate: 0.10588\n",
            "Omega: 0.7, Sigma: 0.075, Attack Rate: 0.10894\n",
            "Omega: 0.7, Sigma: 0.1, Attack Rate: 0.1007\n",
            "Omega: 0.7, Sigma: 0.125, Attack Rate: 0.10286\n",
            "Omega: 0.7, Sigma: 0.15, Attack Rate: 0.10258\n",
            "Omega: 0.7, Sigma: 0.175, Attack Rate: 0.1036\n",
            "Omega: 0.7, Sigma: 0.2, Attack Rate: 0.10092\n",
            "Omega: 0.7, Sigma: 0.225, Attack Rate: 0.10552\n",
            "Omega: 0.7, Sigma: 0.25, Attack Rate: 0.10122\n",
            "Omega: 0.7, Sigma: 0.275, Attack Rate: 0.1008\n",
            "Omega: 0.7, Sigma: 0.3, Attack Rate: 0.1012\n",
            "Omega: 0.7, Sigma: 0.325, Attack Rate: 0.10726000000000001\n",
            "Omega: 0.7, Sigma: 0.35, Attack Rate: 0.10248\n",
            "Omega: 0.7, Sigma: 0.375, Attack Rate: 0.09916\n",
            "Omega: 0.7, Sigma: 0.4, Attack Rate: 0.09442\n",
            "Omega: 0.7, Sigma: 0.425, Attack Rate: 0.09781999999999999\n",
            "Omega: 0.7, Sigma: 0.45, Attack Rate: 0.10178\n",
            "Omega: 0.7, Sigma: 0.475, Attack Rate: 0.10448\n",
            "Omega: 0.7, Sigma: 0.5, Attack Rate: 0.10016\n",
            "Omega: 0.8, Sigma: 0.0, Attack Rate: 0.11734\n",
            "Omega: 0.8, Sigma: 0.025, Attack Rate: 0.11316\n",
            "Omega: 0.8, Sigma: 0.05, Attack Rate: 0.10854000000000001\n",
            "Omega: 0.8, Sigma: 0.075, Attack Rate: 0.10844\n",
            "Omega: 0.8, Sigma: 0.1, Attack Rate: 0.10118\n",
            "Omega: 0.8, Sigma: 0.125, Attack Rate: 0.1033\n",
            "Omega: 0.8, Sigma: 0.15, Attack Rate: 0.10540000000000001\n",
            "Omega: 0.8, Sigma: 0.175, Attack Rate: 0.10276\n",
            "Omega: 0.8, Sigma: 0.2, Attack Rate: 0.1027\n",
            "Omega: 0.8, Sigma: 0.225, Attack Rate: 0.10272\n",
            "Omega: 0.8, Sigma: 0.25, Attack Rate: 0.1072\n",
            "Omega: 0.8, Sigma: 0.275, Attack Rate: 0.10068\n",
            "Omega: 0.8, Sigma: 0.3, Attack Rate: 0.09595999999999999\n",
            "Omega: 0.8, Sigma: 0.325, Attack Rate: 0.09938\n",
            "Omega: 0.8, Sigma: 0.35, Attack Rate: 0.09916\n",
            "Omega: 0.8, Sigma: 0.375, Attack Rate: 0.1014\n",
            "Omega: 0.8, Sigma: 0.4, Attack Rate: 0.10457999999999999\n",
            "Omega: 0.8, Sigma: 0.425, Attack Rate: 0.107\n",
            "Omega: 0.8, Sigma: 0.45, Attack Rate: 0.10378\n",
            "Omega: 0.8, Sigma: 0.475, Attack Rate: 0.10036\n",
            "Omega: 0.8, Sigma: 0.5, Attack Rate: 0.09831999999999999\n",
            "Omega: 0.9, Sigma: 0.0, Attack Rate: 0.11568\n",
            "Omega: 0.9, Sigma: 0.025, Attack Rate: 0.10582\n",
            "Omega: 0.9, Sigma: 0.05, Attack Rate: 0.11022\n",
            "Omega: 0.9, Sigma: 0.075, Attack Rate: 0.10918000000000001\n",
            "Omega: 0.9, Sigma: 0.1, Attack Rate: 0.10776000000000001\n",
            "Omega: 0.9, Sigma: 0.125, Attack Rate: 0.10268000000000001\n",
            "Omega: 0.9, Sigma: 0.15, Attack Rate: 0.10596\n",
            "Omega: 0.9, Sigma: 0.175, Attack Rate: 0.105\n",
            "Omega: 0.9, Sigma: 0.2, Attack Rate: 0.10044\n",
            "Omega: 0.9, Sigma: 0.225, Attack Rate: 0.09945999999999999\n",
            "Omega: 0.9, Sigma: 0.25, Attack Rate: 0.09344\n",
            "Omega: 0.9, Sigma: 0.275, Attack Rate: 0.1115\n",
            "Omega: 0.9, Sigma: 0.3, Attack Rate: 0.10258\n",
            "Omega: 0.9, Sigma: 0.325, Attack Rate: 0.10376\n",
            "Omega: 0.9, Sigma: 0.35, Attack Rate: 0.09718\n",
            "Omega: 0.9, Sigma: 0.375, Attack Rate: 0.10406\n",
            "Omega: 0.9, Sigma: 0.4, Attack Rate: 0.10194\n",
            "Omega: 0.9, Sigma: 0.425, Attack Rate: 0.1061\n",
            "Omega: 0.9, Sigma: 0.45, Attack Rate: 0.10306\n",
            "Omega: 0.9, Sigma: 0.475, Attack Rate: 0.1027\n",
            "Omega: 0.9, Sigma: 0.5, Attack Rate: 0.10546\n",
            "Omega: 1.0, Sigma: 0.0, Attack Rate: 0.1118\n",
            "Omega: 1.0, Sigma: 0.025, Attack Rate: 0.11636\n",
            "Omega: 1.0, Sigma: 0.05, Attack Rate: 0.10672\n",
            "Omega: 1.0, Sigma: 0.075, Attack Rate: 0.10506\n",
            "Omega: 1.0, Sigma: 0.1, Attack Rate: 0.10584\n",
            "Omega: 1.0, Sigma: 0.125, Attack Rate: 0.10722\n",
            "Omega: 1.0, Sigma: 0.15, Attack Rate: 0.10336\n",
            "Omega: 1.0, Sigma: 0.175, Attack Rate: 0.10348\n",
            "Omega: 1.0, Sigma: 0.2, Attack Rate: 0.10687999999999999\n",
            "Omega: 1.0, Sigma: 0.225, Attack Rate: 0.09806000000000001\n",
            "Omega: 1.0, Sigma: 0.25, Attack Rate: 0.09878\n",
            "Omega: 1.0, Sigma: 0.275, Attack Rate: 0.10443999999999999\n",
            "Omega: 1.0, Sigma: 0.3, Attack Rate: 0.10002\n",
            "Omega: 1.0, Sigma: 0.325, Attack Rate: 0.10076\n",
            "Omega: 1.0, Sigma: 0.35, Attack Rate: 0.10136\n",
            "Omega: 1.0, Sigma: 0.375, Attack Rate: 0.10344\n",
            "Omega: 1.0, Sigma: 0.4, Attack Rate: 0.09988\n",
            "Omega: 1.0, Sigma: 0.425, Attack Rate: 0.10246\n",
            "Omega: 1.0, Sigma: 0.45, Attack Rate: 0.10182\n",
            "Omega: 1.0, Sigma: 0.475, Attack Rate: 0.10104\n",
            "Omega: 1.0, Sigma: 0.5, Attack Rate: 0.09888\n",
            "Omega: 1.1, Sigma: 0.0, Attack Rate: 0.11564\n",
            "Omega: 1.1, Sigma: 0.025, Attack Rate: 0.12201999999999999\n",
            "Omega: 1.1, Sigma: 0.05, Attack Rate: 0.1154\n",
            "Omega: 1.1, Sigma: 0.075, Attack Rate: 0.10876000000000001\n",
            "Omega: 1.1, Sigma: 0.1, Attack Rate: 0.111\n",
            "Omega: 1.1, Sigma: 0.125, Attack Rate: 0.10318000000000001\n",
            "Omega: 1.1, Sigma: 0.15, Attack Rate: 0.10642\n",
            "Omega: 1.1, Sigma: 0.175, Attack Rate: 0.10042\n",
            "Omega: 1.1, Sigma: 0.2, Attack Rate: 0.11123999999999999\n",
            "Omega: 1.1, Sigma: 0.225, Attack Rate: 0.1006\n",
            "Omega: 1.1, Sigma: 0.25, Attack Rate: 0.10438\n",
            "Omega: 1.1, Sigma: 0.275, Attack Rate: 0.10428\n",
            "Omega: 1.1, Sigma: 0.3, Attack Rate: 0.09731999999999999\n",
            "Omega: 1.1, Sigma: 0.325, Attack Rate: 0.09809999999999999\n",
            "Omega: 1.1, Sigma: 0.35, Attack Rate: 0.10218\n",
            "Omega: 1.1, Sigma: 0.375, Attack Rate: 0.1024\n",
            "Omega: 1.1, Sigma: 0.4, Attack Rate: 0.10558\n",
            "Omega: 1.1, Sigma: 0.425, Attack Rate: 0.10758\n",
            "Omega: 1.1, Sigma: 0.45, Attack Rate: 0.1003\n",
            "Omega: 1.1, Sigma: 0.475, Attack Rate: 0.10292\n",
            "Omega: 1.1, Sigma: 0.5, Attack Rate: 0.10112\n",
            "Omega: 1.2, Sigma: 0.0, Attack Rate: 0.11814\n",
            "Omega: 1.2, Sigma: 0.025, Attack Rate: 0.11952\n",
            "Omega: 1.2, Sigma: 0.05, Attack Rate: 0.11774\n",
            "Omega: 1.2, Sigma: 0.075, Attack Rate: 0.1113\n",
            "Omega: 1.2, Sigma: 0.1, Attack Rate: 0.10438\n",
            "Omega: 1.2, Sigma: 0.125, Attack Rate: 0.10687999999999999\n",
            "Omega: 1.2, Sigma: 0.15, Attack Rate: 0.10404000000000001\n",
            "Omega: 1.2, Sigma: 0.175, Attack Rate: 0.09938\n",
            "Omega: 1.2, Sigma: 0.2, Attack Rate: 0.1039\n",
            "Omega: 1.2, Sigma: 0.225, Attack Rate: 0.09974\n",
            "Omega: 1.2, Sigma: 0.25, Attack Rate: 0.09864\n",
            "Omega: 1.2, Sigma: 0.275, Attack Rate: 0.10254\n",
            "Omega: 1.2, Sigma: 0.3, Attack Rate: 0.10512\n",
            "Omega: 1.2, Sigma: 0.325, Attack Rate: 0.09968\n",
            "Omega: 1.2, Sigma: 0.35, Attack Rate: 0.0996\n",
            "Omega: 1.2, Sigma: 0.375, Attack Rate: 0.09774\n",
            "Omega: 1.2, Sigma: 0.4, Attack Rate: 0.09928000000000001\n",
            "Omega: 1.2, Sigma: 0.425, Attack Rate: 0.1047\n",
            "Omega: 1.2, Sigma: 0.45, Attack Rate: 0.10144\n",
            "Omega: 1.2, Sigma: 0.475, Attack Rate: 0.09802\n",
            "Omega: 1.2, Sigma: 0.5, Attack Rate: 0.10184\n",
            "Omega: 1.3, Sigma: 0.0, Attack Rate: 0.12066\n",
            "Omega: 1.3, Sigma: 0.025, Attack Rate: 0.12224\n",
            "Omega: 1.3, Sigma: 0.05, Attack Rate: 0.1093\n",
            "Omega: 1.3, Sigma: 0.075, Attack Rate: 0.10656\n",
            "Omega: 1.3, Sigma: 0.1, Attack Rate: 0.11131999999999999\n",
            "Omega: 1.3, Sigma: 0.125, Attack Rate: 0.10636\n",
            "Omega: 1.3, Sigma: 0.15, Attack Rate: 0.10588\n",
            "Omega: 1.3, Sigma: 0.175, Attack Rate: 0.10326\n",
            "Omega: 1.3, Sigma: 0.2, Attack Rate: 0.09816\n",
            "Omega: 1.3, Sigma: 0.225, Attack Rate: 0.10606\n",
            "Omega: 1.3, Sigma: 0.25, Attack Rate: 0.09931999999999999\n",
            "Omega: 1.3, Sigma: 0.275, Attack Rate: 0.1023\n",
            "Omega: 1.3, Sigma: 0.3, Attack Rate: 0.10362\n",
            "Omega: 1.3, Sigma: 0.325, Attack Rate: 0.09744\n",
            "Omega: 1.3, Sigma: 0.35, Attack Rate: 0.10632\n",
            "Omega: 1.3, Sigma: 0.375, Attack Rate: 0.09781999999999999\n",
            "Omega: 1.3, Sigma: 0.4, Attack Rate: 0.0978\n",
            "Omega: 1.3, Sigma: 0.425, Attack Rate: 0.09998\n",
            "Omega: 1.3, Sigma: 0.45, Attack Rate: 0.09620000000000001\n",
            "Omega: 1.3, Sigma: 0.475, Attack Rate: 0.0985\n",
            "Omega: 1.3, Sigma: 0.5, Attack Rate: 0.09662000000000001\n",
            "Omega: 1.4, Sigma: 0.0, Attack Rate: 0.12236\n",
            "Omega: 1.4, Sigma: 0.025, Attack Rate: 0.12028\n",
            "Omega: 1.4, Sigma: 0.05, Attack Rate: 0.11974\n",
            "Omega: 1.4, Sigma: 0.075, Attack Rate: 0.11102\n",
            "Omega: 1.4, Sigma: 0.1, Attack Rate: 0.11104\n",
            "Omega: 1.4, Sigma: 0.125, Attack Rate: 0.1039\n",
            "Omega: 1.4, Sigma: 0.15, Attack Rate: 0.10822\n",
            "Omega: 1.4, Sigma: 0.175, Attack Rate: 0.10212\n",
            "Omega: 1.4, Sigma: 0.2, Attack Rate: 0.09948\n",
            "Omega: 1.4, Sigma: 0.225, Attack Rate: 0.10552\n",
            "Omega: 1.4, Sigma: 0.25, Attack Rate: 0.10302\n",
            "Omega: 1.4, Sigma: 0.275, Attack Rate: 0.09962\n",
            "Omega: 1.4, Sigma: 0.3, Attack Rate: 0.10534\n",
            "Omega: 1.4, Sigma: 0.325, Attack Rate: 0.10012\n",
            "Omega: 1.4, Sigma: 0.35, Attack Rate: 0.1016\n",
            "Omega: 1.4, Sigma: 0.375, Attack Rate: 0.10486\n",
            "Omega: 1.4, Sigma: 0.4, Attack Rate: 0.09831999999999999\n",
            "Omega: 1.4, Sigma: 0.425, Attack Rate: 0.1018\n",
            "Omega: 1.4, Sigma: 0.45, Attack Rate: 0.09828\n",
            "Omega: 1.4, Sigma: 0.475, Attack Rate: 0.10212\n",
            "Omega: 1.4, Sigma: 0.5, Attack Rate: 0.09998\n",
            "Omega: 1.5, Sigma: 0.0, Attack Rate: 0.11982\n",
            "Omega: 1.5, Sigma: 0.025, Attack Rate: 0.11694\n",
            "Omega: 1.5, Sigma: 0.05, Attack Rate: 0.11418\n",
            "Omega: 1.5, Sigma: 0.075, Attack Rate: 0.10751999999999999\n",
            "Omega: 1.5, Sigma: 0.1, Attack Rate: 0.11302\n",
            "Omega: 1.5, Sigma: 0.125, Attack Rate: 0.10628\n",
            "Omega: 1.5, Sigma: 0.15, Attack Rate: 0.10388\n",
            "Omega: 1.5, Sigma: 0.175, Attack Rate: 0.11\n",
            "Omega: 1.5, Sigma: 0.2, Attack Rate: 0.10108\n",
            "Omega: 1.5, Sigma: 0.225, Attack Rate: 0.10158\n",
            "Omega: 1.5, Sigma: 0.25, Attack Rate: 0.10274\n",
            "Omega: 1.5, Sigma: 0.275, Attack Rate: 0.0996\n",
            "Omega: 1.5, Sigma: 0.3, Attack Rate: 0.1024\n",
            "Omega: 1.5, Sigma: 0.325, Attack Rate: 0.09912\n",
            "Omega: 1.5, Sigma: 0.35, Attack Rate: 0.09714\n",
            "Omega: 1.5, Sigma: 0.375, Attack Rate: 0.1018\n",
            "Omega: 1.5, Sigma: 0.4, Attack Rate: 0.09944\n",
            "Omega: 1.5, Sigma: 0.425, Attack Rate: 0.10464\n",
            "Omega: 1.5, Sigma: 0.45, Attack Rate: 0.10368000000000001\n",
            "Omega: 1.5, Sigma: 0.475, Attack Rate: 0.10354000000000001\n",
            "Omega: 1.5, Sigma: 0.5, Attack Rate: 0.10416\n",
            "Omega: 1.6, Sigma: 0.0, Attack Rate: 0.12265999999999999\n",
            "Omega: 1.6, Sigma: 0.025, Attack Rate: 0.11978\n",
            "Omega: 1.6, Sigma: 0.05, Attack Rate: 0.11362\n",
            "Omega: 1.6, Sigma: 0.075, Attack Rate: 0.11622\n",
            "Omega: 1.6, Sigma: 0.1, Attack Rate: 0.11018\n",
            "Omega: 1.6, Sigma: 0.125, Attack Rate: 0.10579999999999999\n",
            "Omega: 1.6, Sigma: 0.15, Attack Rate: 0.10643999999999999\n",
            "Omega: 1.6, Sigma: 0.175, Attack Rate: 0.10646\n",
            "Omega: 1.6, Sigma: 0.2, Attack Rate: 0.1027\n",
            "Omega: 1.6, Sigma: 0.225, Attack Rate: 0.09809999999999999\n",
            "Omega: 1.6, Sigma: 0.25, Attack Rate: 0.10302\n",
            "Omega: 1.6, Sigma: 0.275, Attack Rate: 0.10474\n",
            "Omega: 1.6, Sigma: 0.3, Attack Rate: 0.10188\n",
            "Omega: 1.6, Sigma: 0.325, Attack Rate: 0.10182\n",
            "Omega: 1.6, Sigma: 0.35, Attack Rate: 0.10154\n",
            "Omega: 1.6, Sigma: 0.375, Attack Rate: 0.10624\n",
            "Omega: 1.6, Sigma: 0.4, Attack Rate: 0.09718\n",
            "Omega: 1.6, Sigma: 0.425, Attack Rate: 0.10214\n",
            "Omega: 1.6, Sigma: 0.45, Attack Rate: 0.10234\n",
            "Omega: 1.6, Sigma: 0.475, Attack Rate: 0.1026\n",
            "Omega: 1.6, Sigma: 0.5, Attack Rate: 0.10056\n",
            "Omega: 1.7, Sigma: 0.0, Attack Rate: 0.12678\n",
            "Omega: 1.7, Sigma: 0.025, Attack Rate: 0.12436\n",
            "Omega: 1.7, Sigma: 0.05, Attack Rate: 0.12248\n",
            "Omega: 1.7, Sigma: 0.075, Attack Rate: 0.12192\n",
            "Omega: 1.7, Sigma: 0.1, Attack Rate: 0.11708\n",
            "Omega: 1.7, Sigma: 0.125, Attack Rate: 0.1124\n",
            "Omega: 1.7, Sigma: 0.15, Attack Rate: 0.10801999999999999\n",
            "Omega: 1.7, Sigma: 0.175, Attack Rate: 0.1065\n",
            "Omega: 1.7, Sigma: 0.2, Attack Rate: 0.10252\n",
            "Omega: 1.7, Sigma: 0.225, Attack Rate: 0.09816\n",
            "Omega: 1.7, Sigma: 0.25, Attack Rate: 0.10368000000000001\n",
            "Omega: 1.7, Sigma: 0.275, Attack Rate: 0.10376\n",
            "Omega: 1.7, Sigma: 0.3, Attack Rate: 0.10640000000000001\n",
            "Omega: 1.7, Sigma: 0.325, Attack Rate: 0.09256\n",
            "Omega: 1.7, Sigma: 0.35, Attack Rate: 0.10038\n",
            "Omega: 1.7, Sigma: 0.375, Attack Rate: 0.10692\n",
            "Omega: 1.7, Sigma: 0.4, Attack Rate: 0.10248\n",
            "Omega: 1.7, Sigma: 0.425, Attack Rate: 0.09698000000000001\n",
            "Omega: 1.7, Sigma: 0.45, Attack Rate: 0.09487999999999999\n",
            "Omega: 1.7, Sigma: 0.475, Attack Rate: 0.10388\n",
            "Omega: 1.7, Sigma: 0.5, Attack Rate: 0.10529999999999999\n",
            "Omega: 1.8, Sigma: 0.0, Attack Rate: 0.12884\n",
            "Omega: 1.8, Sigma: 0.025, Attack Rate: 0.12756\n",
            "Omega: 1.8, Sigma: 0.05, Attack Rate: 0.11674\n",
            "Omega: 1.8, Sigma: 0.075, Attack Rate: 0.12036\n",
            "Omega: 1.8, Sigma: 0.1, Attack Rate: 0.11686\n",
            "Omega: 1.8, Sigma: 0.125, Attack Rate: 0.10959999999999999\n",
            "Omega: 1.8, Sigma: 0.15, Attack Rate: 0.10138\n",
            "Omega: 1.8, Sigma: 0.175, Attack Rate: 0.10416\n",
            "Omega: 1.8, Sigma: 0.2, Attack Rate: 0.10198\n",
            "Omega: 1.8, Sigma: 0.225, Attack Rate: 0.10206\n",
            "Omega: 1.8, Sigma: 0.25, Attack Rate: 0.10086\n",
            "Omega: 1.8, Sigma: 0.275, Attack Rate: 0.1029\n",
            "Omega: 1.8, Sigma: 0.3, Attack Rate: 0.10002\n",
            "Omega: 1.8, Sigma: 0.325, Attack Rate: 0.10640000000000001\n",
            "Omega: 1.8, Sigma: 0.35, Attack Rate: 0.10364\n",
            "Omega: 1.8, Sigma: 0.375, Attack Rate: 0.10954000000000001\n",
            "Omega: 1.8, Sigma: 0.4, Attack Rate: 0.10052\n",
            "Omega: 1.8, Sigma: 0.425, Attack Rate: 0.09834\n",
            "Omega: 1.8, Sigma: 0.45, Attack Rate: 0.10579999999999999\n",
            "Omega: 1.8, Sigma: 0.475, Attack Rate: 0.09845999999999999\n",
            "Omega: 1.8, Sigma: 0.5, Attack Rate: 0.09962\n",
            "Omega: 1.9, Sigma: 0.0, Attack Rate: 0.12318000000000001\n",
            "Omega: 1.9, Sigma: 0.025, Attack Rate: 0.12996000000000002\n",
            "Omega: 1.9, Sigma: 0.05, Attack Rate: 0.12028\n",
            "Omega: 1.9, Sigma: 0.075, Attack Rate: 0.11964\n",
            "Omega: 1.9, Sigma: 0.1, Attack Rate: 0.11778\n",
            "Omega: 1.9, Sigma: 0.125, Attack Rate: 0.10696\n",
            "Omega: 1.9, Sigma: 0.15, Attack Rate: 0.10538\n",
            "Omega: 1.9, Sigma: 0.175, Attack Rate: 0.09508\n",
            "Omega: 1.9, Sigma: 0.2, Attack Rate: 0.10593999999999999\n",
            "Omega: 1.9, Sigma: 0.225, Attack Rate: 0.10522\n",
            "Omega: 1.9, Sigma: 0.25, Attack Rate: 0.10524\n",
            "Omega: 1.9, Sigma: 0.275, Attack Rate: 0.09768\n",
            "Omega: 1.9, Sigma: 0.3, Attack Rate: 0.10402\n",
            "Omega: 1.9, Sigma: 0.325, Attack Rate: 0.1\n",
            "Omega: 1.9, Sigma: 0.35, Attack Rate: 0.10406\n",
            "Omega: 1.9, Sigma: 0.375, Attack Rate: 0.09604\n",
            "Omega: 1.9, Sigma: 0.4, Attack Rate: 0.1022\n",
            "Omega: 1.9, Sigma: 0.425, Attack Rate: 0.09918\n",
            "Omega: 1.9, Sigma: 0.45, Attack Rate: 0.09812\n",
            "Omega: 1.9, Sigma: 0.475, Attack Rate: 0.10596\n",
            "Omega: 1.9, Sigma: 0.5, Attack Rate: 0.10064000000000001\n",
            "Omega: 2.0, Sigma: 0.0, Attack Rate: 0.13326\n",
            "Omega: 2.0, Sigma: 0.025, Attack Rate: 0.12652\n",
            "Omega: 2.0, Sigma: 0.05, Attack Rate: 0.12136\n",
            "Omega: 2.0, Sigma: 0.075, Attack Rate: 0.11588\n",
            "Omega: 2.0, Sigma: 0.1, Attack Rate: 0.11392000000000001\n",
            "Omega: 2.0, Sigma: 0.125, Attack Rate: 0.11106\n",
            "Omega: 2.0, Sigma: 0.15, Attack Rate: 0.10479999999999999\n",
            "Omega: 2.0, Sigma: 0.175, Attack Rate: 0.101\n",
            "Omega: 2.0, Sigma: 0.2, Attack Rate: 0.106\n",
            "Omega: 2.0, Sigma: 0.225, Attack Rate: 0.10536\n",
            "Omega: 2.0, Sigma: 0.25, Attack Rate: 0.10242\n",
            "Omega: 2.0, Sigma: 0.275, Attack Rate: 0.09942000000000001\n",
            "Omega: 2.0, Sigma: 0.3, Attack Rate: 0.10404000000000001\n",
            "Omega: 2.0, Sigma: 0.325, Attack Rate: 0.10356\n",
            "Omega: 2.0, Sigma: 0.35, Attack Rate: 0.09681999999999999\n",
            "Omega: 2.0, Sigma: 0.375, Attack Rate: 0.10418000000000001\n",
            "Omega: 2.0, Sigma: 0.4, Attack Rate: 0.10114\n",
            "Omega: 2.0, Sigma: 0.425, Attack Rate: 0.09752\n",
            "Omega: 2.0, Sigma: 0.45, Attack Rate: 0.09894\n",
            "Omega: 2.0, Sigma: 0.475, Attack Rate: 0.10298\n",
            "Omega: 2.0, Sigma: 0.5, Attack Rate: 0.10088\n",
            "Data has been written.\n"
          ]
        }
      ],
      "source": [
        "import multiprocessing as mp\n",
        "\n",
        "n_iterations = 100\n",
        "\n",
        "omega_range = np.round([i * 0.10 for i in range(21)], 3)\n",
        "sigma_range = np.round([i * 0.025 for i in range(21)], 3)\n",
        "\n",
        "heatmap_data = np.zeros((len(omega_range), len(sigma_range)))\n",
        "\n",
        "def compute_attack_rate(params):\n",
        "    omega, sigma = params\n",
        "    recovered_counts = []\n",
        "\n",
        "    for _ in range(n_iterations):\n",
        "        time_record, recovered_count = ICE_model_record_layer_education(\n",
        "            inw, ldeg_i, ltre, cnw, ldeg_c, lprot, enw, ldeg_e, lam, alp, omega, sigma,\n",
        "            phi, zeta_1, zeta_2, zeta_3, zeta_4, beta_PP, beta_NP, beta_PN, beta_NN, mu, n_sample\n",
        "        )\n",
        "        final_recovered_count = recovered_count[-1]\n",
        "        recovered_counts.append(final_recovered_count)\n",
        "\n",
        "    attack_rate = np.mean(recovered_counts) / 500\n",
        "    return omega, sigma, attack_rate\n",
        "\n",
        "params_list = [(omega, sigma) for omega in omega_range for sigma in sigma_range]\n",
        "\n",
        "with mp.Pool(processes=mp.cpu_count()) as pool:\n",
        "    results = pool.map(compute_attack_rate, params_list)\n",
        "\n",
        "for omega, sigma, attack_rate in results:\n",
        "    i = np.where(omega_range == omega)[0][0]\n",
        "    j = np.where(sigma_range == sigma)[0][0]\n",
        "    heatmap_data[i, j] = attack_rate\n",
        "    print(f\"Omega: {omega}, Sigma: {sigma}, Attack Rate: {attack_rate}\")\n",
        "\n",
        "\n",
        "# Store data\n",
        "import csv\n",
        "file_path = '/content/drive/My Drive/Information_Behavior_Disease_Networks/heat_map_results/Fig_7B_more_steps.csv'\n",
        "with open(file_path, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    header = ['Omega \\\\ Sigma'] + sigma_range.tolist()\n",
        "    writer.writerow(header)\n",
        "\n",
        "    for i, omega in enumerate(omega_range):\n",
        "        row = [omega] + heatmap_data[i].tolist()\n",
        "        writer.writerow(row)\n",
        "\n",
        "print(f\"Data has been written.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}